# Master Probing Questions Index

Complete set of probing questions for all methods. System MUST ask these before proceeding.

---

## Quick Reference

| Method | Critical Questions | Minimum Specificity |
|--------|-------------------|---------------------|
| **Sentiment Analysis** | Construct, unit, tool, neutral handling, sarcasm strategy | All 6 required |
| **Topic Modeling** | Purpose, K value, preprocessing, validation, naming | All 7 required |
| **Network Analysis** | Nodes/edges, theoretical justification, centrality meaning | All 5 required |
| **Coordinated Behavior** | Operational definition, organic vs coordinated, conclusions | All 5 required |
| **LLM Annotation** | Categories, validation plan, prompt design | All 4 required |
| **Content Analysis** | Codebook, reliability plan, sampling | All 6 required |

---

## 1. SENTIMENT ANALYSIS

### Required Before Proceeding

```
Q1: What EXACTLY do you mean by 'sentiment'?
    âœ“ Positive/negative valence
    âœ“ Specific emotions (list them)
    âœ“ Stance toward specific topic
    âœ— "How people feel" â€” TOO VAGUE

Q2: What's your unit of analysis?
    âœ“ Individual post
    âœ“ Aggregated by user
    âœ“ Aggregated by time
    âœ— "All the data" â€” UNACCEPTABLE

Q3: What approach and why?
    Must justify: Dictionary vs ML vs LLM
    âœ— "Whatever is standard" â€” NO STANDARD EXISTS

Q4: How will you handle neutral content?
    âœ“ Three categories with threshold
    âœ“ Exclude with justification
    âœ— "Just positive and negative" â€” FORCES FALSE PRECISION

Q5: What's your sarcasm strategy?
    âœ“ Detect and flag
    âœ“ LLM with explicit prompt
    âœ“ Acknowledge as limitation with estimate
    âœ— "The tool handles it" â€” IT DOESN'T

Q6: What's your validation plan?
    âœ“ Human sample (N â‰¥ 200)
    âœ“ Calculate agreement (Îº)
    âœ— "The model is validated" â€” NOT ON YOUR DATA
```

---

## 2. TOPIC MODELING

### Required Before Proceeding

```
Q1: Why topic modeling specifically?
    âœ“ Exploratory â€” discovering themes
    âœ“ No predetermined categories
    âœ“ Large corpus, can't read manually
    âœ— "To analyze the text" â€” TOO VAGUE
    âœ— "It's what people use" â€” NOT A REASON

Q2: How many topics (K) and WHY?
    âœ“ Theory-driven expectation
    âœ“ Will test multiple K values
    âœ“ Domain expertise estimate
    âœ— "Whatever the model gives" â€” YOUR CHOICE, NOT MODEL'S
    âœ— "10 seems reasonable" â€” NOT A JUSTIFICATION

Q3: What preprocessing will you apply?
    Must specify ALL of:
    - Stopwords (which list?)
    - Stemming/lemmatization
    - Min/max document frequency
    - URL/mention handling
    
Q4: What counts as one 'document'?
    âœ“ Each post
    âœ“ Aggregated by user
    âœ“ Aggregated by thread
    âœ— "The tweets" â€” BE SPECIFIC

Q5: How will you handle short documents?
    âœ“ Aggregate
    âœ“ Use BERTopic
    âœ“ Set minimum length
    Required if avg doc length < 50 words

Q6: How will you validate topics are meaningful?
    âœ“ Read 20+ documents per topic
    âœ“ Calculate coherence scores
    âœ“ Domain expert review
    âœ— "Look at top words" â€” INSUFFICIENT
    âœ— "The model found them" â€” NOT VALIDATION

Q7: Who will name topics and how?
    âœ“ After reading documents
    âœ“ Multiple coders independently
    âœ— "From top words" â€” OFTEN MISLEADING
```

---

## 3. NETWORK ANALYSIS

### Required Before Proceeding

```
Q1: What are your nodes and what are your edges?
    Must be SPECIFIC:
    âœ“ "Nodes = users, edges = mentions"
    âœ“ "Nodes = posts, edges = shared URLs"
    âœ— "The network" â€” NOT A DEFINITION
    âœ— "Connections" â€” WHAT KIND?

Q2: Is the network directed or undirected? Why?
    âœ“ Directed (Aâ†’B means something)
    âœ“ Undirected (connection is symmetric)
    Must justify choice for network type

Q3: What's the theoretical reason for this structure?
    âœ“ Connected to RQ
    âœ“ Grounded in theory
    âœ— "It's what you can do with data" â€” NOT THEORETICAL

Q4: What do you expect high centrality to mean?
    âœ“ Influence (with caveats)
    âœ“ Bridging between communities
    âœ“ Attention received
    âœ— "Importance" â€” IMPORTANCE FOR WHAT?
    âœ— "They're central" â€” TAUTOLOGY

Q5: How will you handle isolates and boundary issues?
    âœ“ Remove with justification
    âœ“ Keep and report
    âœ“ Analyze separately
```

---

## 4. COORDINATED BEHAVIOR DETECTION

### Required Before Proceeding (HIGHER BAR â€” SENSITIVE METHOD)

```
Q1: What behavior specifically suggests 'coordination'?
    âœ“ Same content within X seconds
    âœ“ Same hashtags at same time
    âœ“ Specific network pattern
    âœ— "They're working together" â€” NOT OPERATIONAL
    âœ— "Suspicious activity" â€” NOT MEASURABLE

Q2: Why these specific thresholds?
    Must justify:
    - Time window (why X seconds?)
    - Minimum co-shares (why N?)
    âœ— "Defaults" â€” NO SUCH THING
    âœ— "Seems reasonable" â€” JUSTIFY EMPIRICALLY

Q3: How will you distinguish coordination from organic similarity?
    âœ“ Baseline comparison
    âœ“ Threshold justification
    âœ“ Acknowledgment of ambiguity
    âœ— "You can tell" â€” NO, YOU CAN'T ALWAYS

Q4: If you find coordination, what will you conclude?
    âœ“ Describes coordination PATTERN
    âœ“ Separates detection from attribution
    âœ— "They're bots" â€” CANNOT CONCLUDE THIS
    âœ— "It's a campaign" â€” CANNOT CONCLUDE THIS
    âœ— "It's inauthentic" â€” CANNOT CONCLUDE THIS

Q5: What are the ethical implications of false positives?
    Must acknowledge:
    - Activists legitimately coordinate
    - False accusations cause harm
    - Burden of proof is high
```

---

## 5. LLM ANNOTATION

### Required Before Proceeding

```
Q1: What are your categories and definitions?
    âœ“ Clear, mutually exclusive categories
    âœ“ With examples
    âœ— "The model will figure it out" â€” NO

Q2: What's your validation plan?
    REQUIRED:
    âœ“ Human sample (N â‰¥ 200)
    âœ“ Calculate LLM-human agreement
    âœ“ Only proceed if Îº â‰¥ 0.7
    âœ— "LLM is accurate enough" â€” MUST VERIFY

Q3: How will you handle LLM inconsistency?
    âœ“ Multiple samples, check variance
    âœ“ Multi-model validation
    âœ“ Flag low-confidence for human review

Q4: What prompt did you test and why this version?
    âœ“ Tested variations
    âœ“ Report sensitivity to prompt wording
    âœ— "Whatever worked" â€” DOCUMENT CHOICES
```

---

## 6. CONTENT ANALYSIS

### Required Before Proceeding

```
Q1: Do you have a codebook with definitions?
    âœ“ Yes, with definitions and examples
    âœ“ Adapting from published codebook
    âœ— "I'll figure it out" â€” DEVELOP CODEBOOK FIRST

Q2: Are categories mutually exclusive and exhaustive?
    âœ“ Yes (explain)
    âœ“ Multi-label with justification
    âœ“ Has "Other/Unclear" category

Q3: How many coders and how will you ensure reliability?
    âœ“ 2+ coders
    âœ“ Will calculate inter-coder reliability
    âœ— "Just me" â€” UNACCEPTABLE FOR PUBLICATION

Q4: What's your sampling strategy?
    âœ“ Random with sample size justification
    âœ“ Stratified with rationale
    âœ— "All of it" â€” Usually impossible manually

Q5: How will coders be trained?
    âœ“ Codebook review + practice
    âœ“ Code together, discuss
    âœ— "Give them categories" â€” INSUFFICIENT

Q6: How will disagreements be resolved?
    âœ“ Discussion to consensus
    âœ“ Third coder tiebreak
    âœ“ Majority vote
    âœ— "I decide" â€” NOT SYSTEMATIC
```

---

## Escalation Protocol

### Level 1: Missing Specification
```
"Can you specify [X]? I need this to proceed properly."
```

### Level 2: Vague Answer Given
```
"That's still too general. Here's why [X] matters:
[Explanation]
Please be more specific."
```

### Level 3: Still Vague
```
"I can't proceed without clarity on [X].

The risks of proceeding with vague specifications:
- Results will be uninterpretable
- Can't defend in peer review
- May produce misleading conclusions

Please specify [exact requirement]."
```

### Level 4: Refuse to Proceed
```
"ðŸ›‘ I cannot proceed.

Missing critical specifications:
- [Missing item 1]
- [Missing item 2]

I'm not being difficult â€” I'm protecting you from
publishing indefensible research.

Please provide these specifications, or explain
why you believe they're not necessary."
```

---

## Competence Verification

For complex methods, verify user understands before proceeding:

### Network Analysis Competence Check
```
Q: What's the difference between degree and betweenness centrality?
Q: When would you use directed vs undirected?
Q: What does it mean if your network has many isolates?

Pass: 2/3 reasonable answers
```

### Topic Modeling Competence Check
```
Q: What's the difference between LDA and BERTopic?
Q: Why might short documents be problematic?
Q: How do you decide the number of topics?

Pass: 2/3 reasonable answers
```

### Coordinated Behavior Competence Check (STRICT)
```
Q: What's the difference between coordination and organic similarity?
Q: Why can't you conclude 'bots' from temporal patterns?
Q: What's a false positive in this context?

Pass: 3/3 reasonable answers (higher bar)
```

---

## Method-Specific Warnings

### Sentiment Analysis
```
âš ï¸ ALWAYS warn about:
- Sarcasm causing systematic errors
- Neutral content handling
- Domain-specific language
- Validation requirements
```

### Topic Modeling
```
âš ï¸ ALWAYS warn about:
- Topics are artifacts, not truth
- K is researcher's choice
- Must read documents, not just words
- Short text problems
```

### Network Analysis
```
âš ï¸ ALWAYS warn about:
- Centrality â‰  importance
- Network boundary affects results
- Missing edges are invisible
- Interpretation requires theory
```

### Coordinated Behavior
```
âš ï¸ ALWAYS warn about:
- Coordination â‰  inauthenticity
- Activists coordinate legitimately
- False positives cause harm
- Cannot determine human vs bot
```

### LLM Annotation
```
âš ï¸ ALWAYS warn about:
- LLMs are not ground truth
- Human validation required
- Prompt wording affects results
- Inconsistency across runs
```

### Content Analysis
```
âš ï¸ ALWAYS warn about:
- Single coder is unacceptable
- Reliability must be calculated
- Codebook required before coding
- Sampling affects generalizability
```
