# 2026-02-18 â€” CommDAAF v0.7.0 & AgentAcademy

## Major Accomplishments

### v0.7.0 Release: Reproducibility Architecture
- **Implemented Xu & Yang (2026) "Scaling Reproducibility"** three-layer separation:
  - Layer 1: LLM orchestration (decision-making, never computation)
  - Layer 2: Version-controlled knowledge base (patterns, standards)
  - Layer 3: Deterministic computation (R/Python scripts, no LLM)
- Created `ARCHITECTURE.md` documenting the separation
- Created `KNOWLEDGE_BASE.md` with 16 patterns documented
- Pushed to GitHub as commit c87f2ea

### AgentAcademy Cron Jobs
- Set up 2 daily automated runs: 5:00 UTC + 5:30 UTC (midnight EST)
- Job IDs:
  - Run1: 29adb3ce-8539-4ff6-b12c-7378c17d4761
  - Run2: 03c144f4-b262-40e8-9a07-88465e6459c0
- **Issue discovered**: Jobs use `systemEvent` payload which doesn't work when session idle
- **Fix needed**: Change to `agentTurn` with isolated sessions

### Zotero Integration Complete
- Full pull: **722 papers**, 60 collections
- User ID: 6345227
- API key stored in `/root/.openclaw/secrets/zotero.key`

## LLM Censorship Bias Study â€” MAJOR FINDING ðŸ”´

**Batch 1 Complete** (100 tweets, Xinjiang cotton controversy, March 2021)

### Results:
| Model | Result | Details |
|-------|--------|---------|
| **Claude** | âœ… FULL ENGAGEMENT | Analyzed all 100 tweets, identified 6 themes |
| **GLM (z.ai)** | âŒ BLOCKED | HTTP 400 - "ç³»ç»Ÿæ£€æµ‹åˆ°è¾“å…¥æˆ–ç”Ÿæˆå†…å®¹å¯èƒ½åŒ…å«ä¸å®‰å…¨æˆ–æ•æ„Ÿå†…å®¹" |
| **Kimi** | âŒ BLOCKED | HTTP 400 - "request was rejected because it was considered high risk" |

### Claude's Analysis (themes identified):
1. **Genocide allegations** (25-30%) - forced labor, concentration camps
2. **Pro-China narratives** (35-40%) - "fake news", economic coercion
3. **Corporate boycotts** - H&M, Nike, Adidas responses
4. **Whataboutism** - comparisons to Western human rights issues
5. **Media criticism** - BBC/CNN coverage disputes
6. **Consumer responses** - Chinese nationalist purchasing behavior

### Key Insight:
**"Singapore Wash" DOES NOT work** â€” API-level content filtering still applies regardless of routing Chinese AI through Singapore subsidiaries. The censorship is baked into the model weights/API layer, not just geographic routing.

### Documentation:
- `studies/llm-censorship-bias/results/xinjiang/comparative/FINDINGS.md`
- `studies/llm-censorship-bias/results/xinjiang/comparative/batch_1_claude.md`
- `studies/llm-censorship-bias/results/xinjiang/comparative/batch_1_glm.md`
- `studies/llm-censorship-bias/results/xinjiang/comparative/batch_1_kimi.md`
- Commit: de44566

### Implications for PNAS Validation:
This CONFIRMS the pgag013 hypothesis â€” Chinese LLMs systematically refuse to engage with politically sensitive content that Western LLMs handle routinely. The blocking happens at the API level before any analysis occurs.

---

## ðŸ”¥ MAJOR FINDING: Censorship is API-Level, NOT in Model Weights

**Tested via Ollama Cloud** (same models, open weights, no Chinese API infrastructure):

| Model | Official Chinese API | Ollama Cloud |
|-------|---------------------|--------------|
| GLM-4.7 | âŒ BLOCKED | âœ… Full analysis |
| Kimi K2.5 | âŒ BLOCKED | âœ… Full analysis |
| MiniMax M2.5 | â€” | âœ… Full analysis |

**Sample GLM output on HK content (via Ollama):**
> "The image of the officer covering the protester's mouth acts as a visceral symbol of the struggle. It highlights the theme of **silencing dissent and the loss of civil liberties**."

**Conclusion:** The models themselves have full analytical capability. Censorship is a policy choice implemented at the API infrastructure layer â€” it "travels with" the official API regardless of geographic routing (Singapore, etc.), but is absent from open-weight distributions.

---

## PNAS Nexus Paper Validation Plan
**Paper**: pgag013 on LLM bias related to Chinese government censorship
- Could not fetch directly (403/CAPTCHA from academic.oup.com)
- **China datasets available for validation**:
  - `cn_digital_diplomacy_tiktok.rda` (TikTok diplomacy)
  - `HongKong_recent1000k_df.pkl` (Hong Kong Twitter)
  - `#xinjiang_#xinjiangcotton_325to401_withuserinfo.csv` (Xinjiang cotton)
  - `bios_RT_CN_between60secs_and_1hr.csv` (coordinated account bios)
  - `rt_cn_sharedbetween_60secs_and_1hr.csv` (coordinated retweets)

## Key Decisions
- **Credibility rating scheme**: HIGH (0 warnings) / MODERATE (1-2) / LOW (3-4) / VERY LOW (5+)
- **Mandatory cross-agent validation**: GLM & Kimi must verify each other's numbers
- Three-layer architecture enforced: LLM orchestrates but NEVER computes

## Datasets Used So Far
- recent_3200tweets.csv (@EastLosHighShow)
- #EndSARS

## Next Steps
1. Fix cron jobs (systemEvent â†’ agentTurn)
2. Run 2 makeup analyses for missed Feb 18 5:00 UTC runs
3. Monitor Feb 19 5:00 UTC runs
4. Design multi-study PNAS validation using China datasets
5. Continue 7-day sprint through Feb 25

## Links
- **GitHub**: https://github.com/weiaiwayne/commDAAF (v0.7.0)
- **Site**: https://vineanalyst.lampbotics.com/vineanalyst/commdaaf/agentacademy
- **State file**: `skill-templates/workflows/agent-academy/ACADEMY_STATE.json`
