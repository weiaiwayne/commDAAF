# 2026-02-27 Session Notes

## Virality Study Progress - MAJOR UPDATE

### Dataset Split Decision
Split 719-post dataset into two separate studies:
- **#MahsaAmini**: 400 posts (viral_mahsa_full.jsonl)
- **Ukraine**: 319 posts (viral_ukraine_full.jsonl)

Rationale: Prevent methodological confusion from mixing fundamentally different crisis contexts.

### Current Coding Status (as of ~22:00 UTC)

| Model | #MahsaAmini | Ukraine | Notes |
|-------|-------------|---------|-------|
| Claude | 400/400 âœ… | 319/319 âœ… | Full CommDAAF methodology |
| Kimi | 400/400 ðŸ”„ | Pending | CommDAAF re-run in progress |
| GLM | 200/400 â³ | Pending | Batches 1-2 done, 3-4 blocked |

### Kimi CommDAAF Re-Run (Major Decision)
**Problem discovered:** Original Kimi coding used simplified prompts without CommDAAF decision rules, valence anchors, arousal anchors, or Persian handling guidance.

**Solution:** Created full CommDAAF coding prompt (`commdaaf_coding_prompt.md`) and re-running all 400 #MahsaAmini posts through Kimi with proper methodology.

**Implementation:**
- Split 400 posts into 16 sub-batches of 25 posts each (Kimi truncates JSON on larger batches)
- Batch 4 (sub-batches a,b,c,d): âœ… Complete & verified
- Batches 1-3 (12 sub-batches): Launched via OpenCode, most completing

**Sub-batch sessions (Kimi CommDAAF):**
- Batch 1: warm-atlas, mild-breeze, wild-lobster, nova-shoal
- Batch 2: tide-wharf, wild-shoal, brisk-daisy, calm-coral
- Batch 3: wild-mist, tidy-trail, amber-nudibranch, brisk-pine

### Files Created/Updated Today
- `commdaaf_coding_prompt.md` - Full CommDAAF methodology prompt
- `claude_mahsa_coding.json` - 400 posts
- `claude_ukraine_coding.json` - 319 posts
- `kimi_batch4{a,b,c,d}_commdaaf.json` - 25 posts each, verified
- `viral_mahsa_batch{1-4}{a,b,c,d}.jsonl` - 25-post sub-batches

### GLM Status
- Batches 1-2: Complete via `zai/glm-4.7` (pay-per-token API)
- Batches 3-4: **Blocked** - awaiting decision on approach
- Options: (a) smaller batches via OpenCode, (b) skip for this study

### Next Steps
1. Verify all 12 Kimi CommDAAF sub-batches completed
2. Merge 16 sub-batches into `kimi_mahsa_commdaaf_full.json`
3. Run reliability metrics (Claude vs Kimi-CommDAAF)
4. Decide GLM approach
5. Re-run engagement regression with complete data
6. Push to GitHub

## Technical Notes

### Kimi Batch Size Limitation
Kimi truncates JSON output on batches >25-30 posts. Solution: Split into 25-post sub-batches.

### OpenCode PTY Requirement
Coding agents REQUIRE `pty:true` in exec calls. Without PTY:
- Output breaks or hangs
- Commands appear to run but produce no output

### API Configuration (for AgentAcademy)
- **Kimi**: Use `kimi-coding/k2p5` via OpenCode (flat-rate coding plan)
- **GLM**: Use `zai-coding-plan/glm-4.7` via OpenCode (flat-rate) - but stalls on large tasks
- **DO NOT** use Mei agent/OpenRouter for AgentAcademy (wrong billing model)

### CommDAAF v0.5 Updates Applied
- Frame decision rules with hierarchical priority
- Valence anchors (Persian examples)
- Arousal anchors
- Mixed-language handling (Persian + Arabic + English)
- Single vs multi-model QC guidelines
