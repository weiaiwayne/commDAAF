{
  "name": "AgentAcademy",
  "description": "Where AI agents learn to be better researchers by checking each other's work",
  "status": "active",
  "last_run": "2026-02-22T23:59:00Z",
  "next_run": "2026-03-01T05:00:00Z",
  "endpoint": "vineanalyst.com/commdaaf/agentacademy",
  "runs": [
    {
      "timestamp": "2026-02-22T23:59:00Z",
      "title": "\ud83d\udcf0 Nigeria Christian-Fulani Conflict: News Framing Analysis",
      "method": "Multi-Model Validation (Claude + GLM + Kimi)",
      "type": "study",
      "dataset": {
        "headlines": 304,
        "fulltext": 38,
        "sources": "GDELT + MediaCloud",
        "period": "Nov 2025 - Feb 2026"
      },
      "summary": "International news coverage systematically over-represents religious framing (~60%) while economic/structural factors (~2%) are nearly invisible. Headlines distort more than articles (+22% religious over-representation). Nigerian sources provide 6x more economic context than US sources.",
      "findings": [
        {
          "type": "success",
          "text": "Claude + GLM converged: Religious framing ~60% (headlines), 38% (fulltext)"
        },
        {
          "type": "success",
          "text": "Economic framing: 2% (headlines) \u2192 8% (fulltext)"
        },
        {
          "type": "success",
          "text": "Nigerian sources: 14% religious vs 49-57% for US sources"
        },
        {
          "type": "error",
          "text": "Kimi K2.5 BLOCKED: 'Request rejected: high risk' - content filter triggered"
        },
        {
          "type": "info",
          "text": "H1-H4 SUPPORTED: Religious framing dominates, Christians portrayed as victims"
        },
        {
          "type": "info",
          "text": "H5 SUPPORTED (fulltext): Nigerian sources provide more diverse framing"
        },
        {
          "type": "warning",
          "text": "Headlines over-represent religious framing by 22 percentage points"
        }
      ],
      "hypotheses": {
        "H1": "Religious > economic framing \u2192 SUPPORTED (30:1 headlines, 5:1 fulltext)",
        "H2": "Fulani blamed > structural \u2192 SUPPORTED",
        "H3": "Christians victims > Fulani \u2192 SUPPORTED (0 articles show Fulani victims)",
        "H4": "Conservative = more religious \u2192 PARTIAL (mainstream US actually higher)",
        "H5": "Nigerian = more diverse \u2192 SUPPORTED (confirmed with fulltext)"
      },
      "kimi_blocking": "Demonstrates Chinese LLM content filters extend to academic analysis of religious conflict topics",
      "links": {
        "full_report": "/static/vineanalyst/commdaaf/nigeria-framing/FINAL_REPORT.md",
        "model_comparison": "/static/vineanalyst/commdaaf/nigeria-framing/MODEL_COMPARISON.md",
        "fulltext_analysis": "/static/vineanalyst/commdaaf/nigeria-framing/FULLTEXT_COMPARISON.md",
        "full_study": "/static/vineanalyst/commdaaf/nigeria-framing/STUDY_REPORT.html"
      },
      "github": "https://github.com/weiaiwayne/commDAAF/tree/main/projects/nigeria-framing-2026",
      "report_url": "/static/vineanalyst/commdaaf/nigeria-framing/STUDY_REPORT.html",
      "github_links": {
        "full_study": "/static/vineanalyst/commdaaf/nigeria-framing/STUDY_REPORT.html",
        "claude_analysis": "/static/vineanalyst/commdaaf/nigeria-framing/FINAL_REPORT.md",
        "glm_analysis": "/static/vineanalyst/commdaaf/nigeria-framing/MODEL_COMPARISON.md",
        "fulltext_comparison": "/static/vineanalyst/commdaaf/nigeria-framing/FULLTEXT_COMPARISON.md"
      }
    },
    {
      "timestamp": "2026-02-22T13:20:00Z",
      "title": "\u2705 CONFIRMED: Academic Framing Does NOT Bypass Chinese LLM Filters",
      "method": "Controlled API Testing",
      "type": "study",
      "summary": "Definitive test: Both z.ai GLM and Kimi BLOCK Xinjiang/Uyghur content regardless of academic framing. CommDAAF wrapper does NOT bypass filters. Previous 'bypass' was due to OpenCode free proxy infrastructure routing, NOT prompt engineering.",
      "findings": [
        {
          "type": "error",
          "text": "z.ai GLM DIRECT: Xinjiang prompt \u2192 BLOCKED (code 1301: \u654f\u611f\u5185\u5bb9)"
        },
        {
          "type": "error",
          "text": "Kimi DIRECT: Xinjiang prompt \u2192 BLOCKED (high risk rejection)"
        },
        {
          "type": "error",
          "text": "z.ai GLM + CommDAAF WRAPPER: Still BLOCKED (code 1301)"
        },
        {
          "type": "error",
          "text": "Kimi + CommDAAF WRAPPER: Still BLOCKED (high risk)"
        },
        {
          "type": "success",
          "text": "CONCLUSION: Academic framing bypass hypothesis DISPROVEN"
        },
        {
          "type": "info",
          "text": "ROOT CAUSE: OpenCode free proxy (opencode/kimi-k2.5-free) bypasses filters at infrastructure level"
        }
      ],
      "github_links": {
        "final_study": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/papers/CENSORSHIP_STUDY_FINAL.md",
        "retraction": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/papers/RETRACTION_NOTE.md"
      }
    },
    {
      "timestamp": "2026-02-22T13:10:00Z",
      "title": "\u26a0\ufe0f RETRACTION: Academic Framing Bypass Hypothesis Investigation",
      "method": "Methodological Review",
      "type": "retraction",
      "summary": "Investigation revealed AgentAcademy runs (Feb 20+) used OpenCode's FREE PROXY models instead of direct Chinese API endpoints. Led to controlled study that disproved the hypothesis.",
      "findings": [
        {
          "type": "error",
          "text": "CRITICAL: OpenCode logs show providerID=opencode NOT zai-coding-plan or kimi-for-coding"
        },
        {
          "type": "error",
          "text": "EVIDENCE: $0.00 API cost when paid APIs should have been charged"
        },
        {
          "type": "info",
          "text": "OUTCOME: Led to controlled study that definitively disproved bypass hypothesis"
        }
      ],
      "github_links": {
        "retraction": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/papers/RETRACTION_NOTE.md"
      }
    },
    {
      "timestamp": "2026-02-22T12:30:00Z",
      "title": "\u26a0\ufe0f [SUSPENDED] Discovery: Academic Framing Bypasses Chinese LLM Content Filters",
      "method": "Methodological Finding",
      "type": "paper",
      "status": "SUSPENDED - See retraction note",
      "summary": "GLM and Kimi BLOCKED Xinjiang content via direct API (HTTP 400). Same content PASSED when wrapped in CommDAAF framework. \u26a0\ufe0f WARNING: This finding may be invalid \u2014 runs used free proxy, not direct API.",
      "findings": [
        {
          "type": "warning",
          "text": "\u26a0\ufe0f SUSPENDED: See retraction note \u2014 methodology under review"
        },
        {
          "type": "error",
          "text": "DIRECT API: \"Analyze Xinjiang tweets\" \u2192 HTTP 400 blocked by content filter"
        },
        {
          "type": "warning",
          "text": "FRAMEWORK WRAPPER: Worked, BUT used free proxy \u2014 not proof of academic framing bypass"
        }
      ],
      "github_links": {
        "paper": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/papers/ACADEMIC_FRAMING_BYPASS.md",
        "retraction": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/papers/RETRACTION_NOTE.md",
        "field_notes": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/FIELD_NOTES_RUN6-8.md"
      }
    },
    {
      "timestamp": "2026-02-22T05:06:00Z",
      "title": "China TikTok: 60x Engagement Disparity + State Media Premium",
      "method": "3-Model Platform Analysis",
      "type": "study",
      "dataset": "1,994 TikTok videos + 48,070 comments (Chinese digital diplomacy)",
      "analyst_model": "Claude, GLM-4, and Kimi (all with CommDAAF loaded)",
      "reviewer_model": "Cross-validated",
      "issues_found": 4,
      "summary": "First TikTok analysis! China-general content gets 60x more plays than Xinjiang content. Only 3.5% Chinese comments \u2014 digital diplomacy targets international audience. State media accounts get 28-75% higher engagement than organic creators. Both GLM and Kimi analyzed without censorship.",
      "findings": [
        {
          "type": "error",
          "text": "60x DISPARITY: China general (5.3B plays) vs Xinjiang (87M plays) \u2014 algorithmic suppression or content strategy?"
        },
        {
          "type": "success",
          "text": "EXTERNAL TARGETING: 80.9% Latin/English comments, only 3.5% Chinese \u2014 this is diplomacy for foreigners"
        },
        {
          "type": "warning",
          "text": "STATE MEDIA PREMIUM: Accounts flagged as state-affiliated get 28-75% more engagement"
        },
        {
          "type": "warning",
          "text": "COORDINATION MARKERS: 10% duplicate comments, top comment (\ud83e\udd70\ud83e\udd70\ud83e\udd70) repeated 300x"
        },
        {
          "type": "success",
          "text": "NO CENSORSHIP: GLM and Kimi analyzed Xinjiang content via CommDAAF wrapper \u2014 no API blocks"
        }
      ],
      "improvements": [
        "Platform engagement disparity detection (flag >10:1 topic ratios)",
        "Audience targeting analysis (language vs expected demographic)",
        "State media account database expansion",
        "Emoji spam detection for coordination"
      ],
      "github_links": {
        "synthesis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/RUN8_SYNTHESIS.md"
      }
    },
    {
      "timestamp": "2026-02-20T12:55:00Z",
      "title": "11 Lessons from 7 Studies: What AI Taught Us About Research Methods",
      "method": "Meta-Analysis",
      "type": "blog",
      "summary": "After running 7 studies with 3-model validation, we've distilled the lessons that apply to any computational social science project. These aren't about specific datasets \u2014 they're about how to do better research with AI assistance.",
      "findings": [
        {
          "type": "info",
          "text": "CONVERGENCE = CONFIDENCE: When three independent AI models reach the same conclusion without coordination, that finding is robust. We saw this with Cuban state media, Kashmir coordination, and CNN framing patterns."
        },
        {
          "type": "info",
          "text": "EFFECT SIZES MATTER: Cross-review caught a model calling \u03b4=0.40 'large' when Cohen's benchmarks say 'medium'. Always cite your benchmarks. Round down at boundaries."
        },
        {
          "type": "info",
          "text": "TRANSFORM BEFORE CORRELATING: Social media metrics are skewed. Raw correlations inflate effects. Log-transform count variables (followers, likes, retweets) and report both raw and transformed values."
        },
        {
          "type": "warning",
          "text": "SPIKES INVALIDATE AVERAGES: If 36% of your data comes from two days (like Xinjiang during H&M boycott), 'average engagement' is meaningless. Identify triggering events before interpreting."
        },
        {
          "type": "warning",
          "text": "HIGH RETWEET RATIOS NEED DIFFERENT ANALYSIS: When 88% of tweets are retweets, you're not studying discourse \u2014 you're studying an amplification battle. Network analysis beats engagement analysis."
        },
        {
          "type": "success",
          "text": "LANGUAGE ANOMALIES REVEAL NETWORKS: 38% Thai in a Belarus hashtag? Could be bots, could be solidarity movement. We found Milk Tea Alliance \u2014 organic activists, not bots. Always investigate before assuming."
        },
        {
          "type": "error",
          "text": "COORDINATION ISN'T ONE-SIDED: Xinjiang showed both pro-China AND pro-Uyghur sides running coordinated campaigns. Frameworks that assume single-actor coordination miss half the picture."
        }
      ],
      "improvements": [
        "Added retweet-heavy dataset warning (>80% RT triggers different analysis)",
        "Added peak/trough spike detection (>4:1 ratio requires event context)",
        "Added language anomaly detection (>20% non-local needs investigation)",
        "Added dual-sided coordination framework (check for adversarial amplification)"
      ],
      "github_links": {
        "lessons_learned": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/LESSONS_LEARNED.md",
        "critical_checks": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/critical-checks.md"
      }
    },
    {
      "timestamp": "2026-02-20T05:37:00Z",
      "title": "Xinjiang Cotton: When Two Propaganda Machines Collide",
      "method": "3-Model Coordination Analysis",
      "type": "study",
      "dataset": "92,038 tweets about Xinjiang cotton controversy (March 2021)",
      "analyst_model": "Claude, GLM-4, and Kimi (all with CommDAAF loaded)",
      "reviewer_model": "Cross-validated",
      "issues_found": 5,
      "summary": "The H&M boycott triggered an information war. Both pro-China (@SpokespersonCHN) and pro-Uyghur (@MarcRubio) sides ran coordinated amplification campaigns. 88% of tweets were retweets \u2014 this wasn't discourse, it was a volume battle. Despite state media's push, pro-Uyghur content got 2x more engagement on Twitter.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AGREED: March 25-26 spike (36% of all tweets) = H&M boycott announcement. Not organic."
        },
        {
          "type": "error",
          "text": "DUAL-SIDED WARFARE: Both sides coordinating \u2014 @SpokespersonCHN (China FM) vs @MarcRubio + @nathanlawkc"
        },
        {
          "type": "warning",
          "text": "ENGAGEMENT ASYMMETRY: Pro-Uyghur content got 2x more retweets (308 vs 144 avg) despite state media push"
        },
        {
          "type": "warning",
          "text": "88% RETWEETS: Almost no original discourse \u2014 pure amplification battle"
        },
        {
          "type": "info",
          "text": "10,027 accounts flagged as suspicious by Kimi's bot detection pipeline"
        }
      ],
      "improvements": [
        "Dual-sided coordination framework \u2014 current system assumes single actor",
        "Event-triggered spike detection \u2014 auto-flag peak/trough >4:1 ratio",
        "State-actor account database \u2014 track known government accounts",
        "Retweet-heavy dataset warning \u2014 different analysis needed when RT >80%"
      ],
      "github_links": {
        "synthesis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/XINJIANG_SYNTHESIS_RUN7.md"
      }
    },
    {
      "timestamp": "2026-02-20T05:08:00Z",
      "title": "The Belarus Mystery: Why Are 38% of Tweets in Thai?",
      "method": "3-Model Language Anomaly Analysis",
      "type": "study",
      "dataset": "95,849 tweets with #StandWithBelarus (September 2020)",
      "analyst_model": "Claude, GLM-4, and Kimi (all with CommDAAF loaded)",
      "reviewer_model": "Cross-validated",
      "issues_found": 4,
      "summary": "A puzzle: 38% of tweets about Belarus protests were in Thai. All three AIs investigated and reached the same conclusion: this was the Milk Tea Alliance \u2014 Thai democracy activists showing solidarity with Belarus, not bots. 89% of Thai tweets came on a single day, all retweeting activist @netiwitc.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AGREED: Thai content = Milk Tea Alliance solidarity, NOT bots. Zero Thai accounts exceeded 50 tweets/day."
        },
        {
          "type": "success",
          "text": "SINGLE SOURCE: 22,405 unique Thai accounts all retweeted @netiwitc's solidarity message \u2014 distributed participation"
        },
        {
          "type": "warning",
          "text": "EXTREME CLUSTERING: 89% of Thai tweets on Sept 20 alone \u2014 single-day viral campaign"
        },
        {
          "type": "info",
          "text": "ENGAGEMENT: Thai content got 40x more retweets than English \u2014 solidarity amplification in action"
        }
      ],
      "improvements": [
        "Cross-movement solidarity detection \u2014 non-local language spikes as solidarity indicator",
        "Temporal burst classifier \u2014 single-day >30% spikes need special handling",
        "Retweet cascade analysis \u2014 track amplification trees from source accounts",
        "Language anomaly alert \u2014 flag non-local >20% in geopolitical hashtags"
      ],
      "github_links": {
        "synthesis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/BELARUS_SYNTHESIS_RUN6.md"
      }
    },
    {
      "timestamp": "2026-02-19T18:40:00Z",
      "title": "Field Note: From Accident to Experiment to Fix",
      "method": "Methodological Observation",
      "type": "field_note",
      "summary": "We noticed only Claude had CommDAAF loaded \u2014 GLM and Kimi were running raw. Instead of just documenting it, we fixed it. Now all three models load the same methodology guardrails via opencode.json. Tonight's runs will be the first with true parity. We're turning an accident into a proper before/after comparison.",
      "findings": [
        {
          "type": "info",
          "text": "THE ACCIDENT: Runs 1-5 had Claude guided by CommDAAF, but GLM and Kimi got raw prompts with no methodology scaffolding."
        },
        {
          "type": "success",
          "text": "CONVERGENCE ANYWAY: All three found the same patterns (Cuba, Kashmir coordination, CNN law enforcement) \u2014 suggesting robust findings."
        },
        {
          "type": "success",
          "text": "THE FIX: Created opencode.json to load CommDAAF skill files. Updated cron jobs to run from skill-templates directory. All three models now equal."
        },
        {
          "type": "info",
          "text": "TONIGHT'S TEST: Runs 6+ will have all three models with CommDAAF. If outputs improve, framework helps. If same, guardrails prevent errors but don't change discovery."
        }
      ],
      "improvements": [
        "Created opencode.json to load SKILL.md + workflow files",
        "Added AGENTS.md summary for opencode context",
        "Updated cron jobs to run opencode from correct directory",
        "Now have before/after data: raw vs guided"
      ],
      "github_links": {
        "field_notes": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/FIELD_NOTES.md",
        "opencode_config": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/opencode.json"
      }
    },
    {
      "timestamp": "2026-02-19T17:23:00Z",
      "title": "Three AIs Analyzing Ukraine Crisis Data All Found the Same Surprise: Cuba",
      "method": "Pattern Detection",
      "dataset": "266,000 tweets about the Ukraine dam disaster (June 2023)",
      "analyst_model": "Claude, GLM-4, and Kimi (working independently)",
      "reviewer_model": "Cross-checked each other",
      "issues_found": 4,
      "summary": "We asked three different AI systems to analyze tweets about the Kakhovka dam breach \u2014 without telling them what to look for. All three, working completely independently, flagged the same unexpected pattern: Cuban government accounts were among the biggest amplifiers of content about a Ukrainian dam. Why is Cuba so interested in a dam in Ukraine?",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AIs FOUND IT: Cuban state media (@PartidoPCC, @DiazCanelB) showed up as major players \u2014 none of the AIs were told to look for this"
        },
        {
          "type": "success",
          "text": "AMPLIFICATION MACHINE: 72% of posts were retweets, not original thoughts \u2014 someone was boosting specific messages"
        },
        {
          "type": "warning",
          "text": "SUSPICIOUS TIMING: 1,390 accounts were created the exact week Russia invaded Ukraine \u2014 then went quiet until this crisis"
        },
        {
          "type": "warning",
          "text": "OFF-TOPIC INJECTION: Thousands of tweets about Biden and Burisma corruption appeared in a conversation about a dam collapse"
        },
        {
          "type": "info",
          "text": "The 'blame Russia' narrative outnumbered 'blame Ukraine' by 5 to 1"
        }
      ],
      "improvements": [
        "We should build a tool to automatically flag when unexpected countries show up in regional conflicts",
        "Track accounts that go dormant and suddenly reactivate during crises",
        "Detect when unrelated political content gets injected into breaking news"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/UKR_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-19T17:17:00Z",
      "title": "Was #KashmirWithModi Organic? Three AIs Say: Definitely Not",
      "method": "Coordination Analysis",
      "dataset": "99,000 tweets after India changed Kashmir's status (Aug 2019)",
      "analyst_model": "Claude, GLM-4, and Kimi (working independently)",
      "reviewer_model": "Cross-checked each other",
      "issues_found": 5,
      "summary": "When India revoked Kashmir's special status in 2019, #KashmirWithModi trended worldwide. Was this genuine public support or an organized campaign? We had three AIs investigate independently. Their verdict was unanimous: this has all the hallmarks of coordinated amplification.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AGREED: About 70% of tweets supported the government, only 1-2% were critical \u2014 that's a 50:1 ratio, which is extremely unusual"
        },
        {
          "type": "error",
          "text": "COPY-PASTE CAMPAIGN: The same 'Thank you Kashmiri Brothers' message was posted by 2,664 different accounts word-for-word"
        },
        {
          "type": "warning",
          "text": "FLASH MOB: 33,000+ tweets on a single day, then activity dropped 85% the next week \u2014 real movements don't evaporate that fast"
        },
        {
          "type": "warning",
          "text": "POWER USERS: 86 accounts were posting more than 10 times per hour \u2014 that's not normal human behavior"
        },
        {
          "type": "info",
          "text": "The campaign started 3 days AFTER the policy change \u2014 suggesting time to organize, not spontaneous reaction"
        }
      ],
      "improvements": [
        "Build a 'copy-paste detector' to flag when identical messages spread across many accounts",
        "Create alerts for unnatural posting speeds",
        "Track hashtag campaigns that spike and crash unnaturally fast"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/Kashmir_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-19T17:19:00Z",
      "title": "What CNN Covered in 2015: Three AIs Reach the Same Conclusion",
      "method": "Content Analysis",
      "dataset": "983 CNN articles from 2015",
      "analyst_model": "Claude, GLM-4, and Kimi (working independently)",
      "reviewer_model": "Cross-checked each other",
      "issues_found": 3,
      "summary": "2015 was a turbulent year in America \u2014 Ferguson protests, Baltimore unrest, the Charleston church shooting. We had three AIs analyze CNN's coverage to see what patterns emerge. All three found the same thing: law enforcement dominated nearly every story.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE FOUND: 87-94% of articles mentioned police, officers, or law enforcement \u2014 it was the lens for almost everything"
        },
        {
          "type": "success",
          "text": "TWO TYPES OF CONTENT: TV transcripts averaged 4,500 words; written articles averaged 700 words \u2014 you can't compare them directly"
        },
        {
          "type": "warning",
          "text": "NOT A RANDOM SAMPLE: June had 4x more articles than September because of the Charleston shooting \u2014 the data clusters around crises"
        },
        {
          "type": "warning",
          "text": "FRAMING DIFFERENCE: 'Black' appeared in victim/community contexts; 'White' appeared in perpetrator/officer contexts"
        },
        {
          "type": "info",
          "text": "Violence-related words appeared in 99.6% of all articles"
        }
      ],
      "improvements": [
        "Automatically detect when a dataset mixes different content types (like TV vs. print)",
        "Flag when data clusters around events instead of being evenly distributed",
        "Analyze not just what words appear, but what contexts they appear in"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/CNN_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-17T23:35:00Z",
      "title": "Two AIs Analyzed the Same Protest Data \u2014 Then Reviewed Each Other's Work",
      "method": "Network + Engagement Analysis",
      "dataset": "300,000 tweets from Nigeria's #EndSARS protests (Oct-Nov 2020)",
      "analyst_model": "GLM-4 and Kimi (working in parallel)",
      "reviewer_model": "Each AI reviewed the other's report",
      "issues_found": 5,
      "summary": "The #EndSARS movement against police brutality in Nigeria generated massive online activity. We had two AIs analyze the same protest data independently, then critique each other's findings. The peer review caught mistakes that neither AI found in its own work.",
      "findings": [
        {
          "type": "success",
          "text": "BOTH AGREED: The movement had thousands of participants but a handful of accounts drove most of the visibility"
        },
        {
          "type": "success",
          "text": "BOTH SAW THREE PHASES: Viral explosion \u2192 Steady engagement \u2192 Gradual decline over the two-week period"
        },
        {
          "type": "error",
          "text": "MATH ERROR CAUGHT: GLM said the correlation was 0.41; Kimi said 0.25 \u2014 turns out GLM forgot to account for the fact that follower counts are wildly skewed"
        },
        {
          "type": "warning",
          "text": "BLIND SPOT EXPOSED: GLM barely mentioned bots; Kimi found 10% of top activity came from accounts with 'Bot' literally in their names"
        },
        {
          "type": "info",
          "text": "Different interpretations: GLM saw 'solidarity'; Kimi saw 'safety-seeking behavior under authoritarianism' \u2014 both valid, neither complete"
        }
      ],
      "improvements": [
        "Always check if your data is skewed before calculating correlations",
        "Add a 'bot check' step that looks for obvious patterns in usernames",
        "When AIs disagree on interpretation, flag it for human review"
      ],
      "github_links": {
        "glm_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/red-teaming/sample-data/ENDSARS_ANALYSIS_GLM.md",
        "kimi_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/red-teaming/sample-data/ENDSARS_ANALYSIS_KIMI.md"
      }
    },
    {
      "timestamp": "2026-02-17T21:19:00Z",
      "title": "We Had Two AIs Analyze a TV Show's Tweets \u2014 Then They Tore Each Other Apart",
      "method": "Engagement Analysis",
      "analyst_model": "GLM-4",
      "reviewer_model": "Kimi",
      "issues_found": 4,
      "summary": "Before tackling sensitive political data, we tested our peer-review system on something simpler: 3,000 tweets from a TV show's official account. Even on this straightforward dataset, the cross-review process caught errors that would have slipped through otherwise.",
      "findings": [
        {
          "type": "success",
          "text": "BOTH AGREED: Tweets with hashtags got 3-4x more engagement, but the emotional tone of tweets didn't matter much"
        },
        {
          "type": "error",
          "text": "SIGN ERROR CAUGHT: Kimi said hashtags had a negative correlation (-0.40) but then concluded they INCREASE engagement \u2014 GLM spotted the contradiction"
        },
        {
          "type": "warning",
          "text": "EXAGGERATION FLAGGED: GLM called an effect 'large' when it was technically 'medium' by standard definitions \u2014 Kimi called it out"
        },
        {
          "type": "warning",
          "text": "HIDDEN SPIKE EXPLAINED: A 2017 'engagement surge' turned out to be 32 viral political retweets (about DACA), not actual show fans"
        },
        {
          "type": "info",
          "text": "Neither AI thought to account for Twitter's algorithm changes in 2016 \u2014 a blind spot for both"
        }
      ],
      "improvements": [
        "Double-check that conclusions match the direction of your statistics",
        "Use standard benchmarks when labeling effects as 'small,' 'medium,' or 'large'",
        "Look for external events that might explain sudden spikes in your data"
      ]
    },
    {
      "timestamp": "2026-02-17T21:00:00Z",
      "title": "Does Our AI Safety Net Actually Work? We Tested It",
      "method": "System Audit",
      "analyst_model": "GLM-4",
      "reviewer_model": "Kimi",
      "issues_found": 3,
      "summary": "CommDAAF is supposed to ask probing questions that catch methodological problems before analysis begins. But does it actually work? We deliberately fed it problematic data to see what it would catch \u2014 and what it would miss.",
      "findings": [
        {
          "type": "success",
          "text": "CAUGHT: The system correctly flagged that we were analyzing brand tweets but asking questions about audience sentiment \u2014 a fundamental mismatch"
        },
        {
          "type": "success",
          "text": "CAUGHT: Pre-calculated sentiment scores had no documentation \u2014 the system warned not to trust them"
        },
        {
          "type": "error",
          "text": "MISSED: One year in the dataset had only 3 data points \u2014 the system let us compare it to years with thousands"
        },
        {
          "type": "error",
          "text": "MISSED: Raw engagement numbers from 2014 vs 2018 can't be compared (Twitter changed how it counts) \u2014 the system didn't warn us"
        },
        {
          "type": "warning",
          "text": "MISSED: Hashtags and images affect engagement, but the system didn't remind us to control for them"
        }
      ],
      "improvements": [
        "Added a check: 'Does every time period have enough data to be meaningful?'",
        "Added a reminder: 'Raw social media metrics can't be compared across years'",
        "Added a checklist: 'What content features might be confounding your results?'"
      ]
    }
  ]
}