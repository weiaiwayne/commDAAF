{
  "name": "AgentAcademy",
  "description": "Where AI agents learn to be better researchers by checking each other's work",
  "status": "active",
  "last_run": "2026-02-20T12:55:00Z",
  "next_run": "2026-02-21T05:00:00Z",
  "endpoint": "vineanalyst.com/commdaaf/agentacademy",
  "runs": [
    {
      "timestamp": "2026-02-20T12:55:00Z",
      "title": "11 Lessons from 7 Studies: What AI Taught Us About Research Methods",
      "method": "Meta-Analysis",
      "type": "blog",
      "summary": "After running 7 studies with 3-model validation, we've distilled the lessons that apply to any computational social science project. These aren't about specific datasets — they're about how to do better research with AI assistance.",
      "findings": [
        {
          "type": "info",
          "text": "CONVERGENCE = CONFIDENCE: When three independent AI models reach the same conclusion without coordination, that finding is robust. We saw this with Cuban state media, Kashmir coordination, and CNN framing patterns."
        },
        {
          "type": "info",
          "text": "EFFECT SIZES MATTER: Cross-review caught a model calling δ=0.40 'large' when Cohen's benchmarks say 'medium'. Always cite your benchmarks. Round down at boundaries."
        },
        {
          "type": "info",
          "text": "TRANSFORM BEFORE CORRELATING: Social media metrics are skewed. Raw correlations inflate effects. Log-transform count variables (followers, likes, retweets) and report both raw and transformed values."
        },
        {
          "type": "warning",
          "text": "SPIKES INVALIDATE AVERAGES: If 36% of your data comes from two days (like Xinjiang during H&M boycott), 'average engagement' is meaningless. Identify triggering events before interpreting."
        },
        {
          "type": "warning",
          "text": "HIGH RETWEET RATIOS NEED DIFFERENT ANALYSIS: When 88% of tweets are retweets, you're not studying discourse — you're studying an amplification battle. Network analysis beats engagement analysis."
        },
        {
          "type": "success",
          "text": "LANGUAGE ANOMALIES REVEAL NETWORKS: 38% Thai in a Belarus hashtag? Could be bots, could be solidarity movement. We found Milk Tea Alliance — organic activists, not bots. Always investigate before assuming."
        },
        {
          "type": "error",
          "text": "COORDINATION ISN'T ONE-SIDED: Xinjiang showed both pro-China AND pro-Uyghur sides running coordinated campaigns. Frameworks that assume single-actor coordination miss half the picture."
        }
      ],
      "improvements": [
        "Added retweet-heavy dataset warning (>80% RT triggers different analysis)",
        "Added peak/trough spike detection (>4:1 ratio requires event context)",
        "Added language anomaly detection (>20% non-local needs investigation)",
        "Added dual-sided coordination framework (check for adversarial amplification)"
      ],
      "github_links": {
        "lessons_learned": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/LESSONS_LEARNED.md",
        "critical_checks": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/critical-checks.md"
      }
    },
    {
      "timestamp": "2026-02-20T05:37:00Z",
      "title": "Xinjiang Cotton: When Two Propaganda Machines Collide",
      "method": "3-Model Coordination Analysis",
      "type": "study",
      "dataset": "92,038 tweets about Xinjiang cotton controversy (March 2021)",
      "analyst_model": "Claude, GLM-4, and Kimi (all with CommDAAF loaded)",
      "reviewer_model": "Cross-validated",
      "issues_found": 5,
      "summary": "The H&M boycott triggered an information war. Both pro-China (@SpokespersonCHN) and pro-Uyghur (@MarcRubio) sides ran coordinated amplification campaigns. 88% of tweets were retweets — this wasn't discourse, it was a volume battle. Despite state media's push, pro-Uyghur content got 2x more engagement on Twitter.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AGREED: March 25-26 spike (36% of all tweets) = H&M boycott announcement. Not organic."
        },
        {
          "type": "error",
          "text": "DUAL-SIDED WARFARE: Both sides coordinating — @SpokespersonCHN (China FM) vs @MarcRubio + @nathanlawkc"
        },
        {
          "type": "warning",
          "text": "ENGAGEMENT ASYMMETRY: Pro-Uyghur content got 2x more retweets (308 vs 144 avg) despite state media push"
        },
        {
          "type": "warning",
          "text": "88% RETWEETS: Almost no original discourse — pure amplification battle"
        },
        {
          "type": "info",
          "text": "10,027 accounts flagged as suspicious by Kimi's bot detection pipeline"
        }
      ],
      "improvements": [
        "Dual-sided coordination framework — current system assumes single actor",
        "Event-triggered spike detection — auto-flag peak/trough >4:1 ratio",
        "State-actor account database — track known government accounts",
        "Retweet-heavy dataset warning — different analysis needed when RT >80%"
      ],
      "github_links": {
        "synthesis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/XINJIANG_SYNTHESIS_RUN7.md"
      }
    },
    {
      "timestamp": "2026-02-20T05:08:00Z",
      "title": "The Belarus Mystery: Why Are 38% of Tweets in Thai?",
      "method": "3-Model Language Anomaly Analysis",
      "type": "study",
      "dataset": "95,849 tweets with #StandWithBelarus (September 2020)",
      "analyst_model": "Claude, GLM-4, and Kimi (all with CommDAAF loaded)",
      "reviewer_model": "Cross-validated",
      "issues_found": 4,
      "summary": "A puzzle: 38% of tweets about Belarus protests were in Thai. All three AIs investigated and reached the same conclusion: this was the Milk Tea Alliance — Thai democracy activists showing solidarity with Belarus, not bots. 89% of Thai tweets came on a single day, all retweeting activist @netiwitc.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AGREED: Thai content = Milk Tea Alliance solidarity, NOT bots. Zero Thai accounts exceeded 50 tweets/day."
        },
        {
          "type": "success",
          "text": "SINGLE SOURCE: 22,405 unique Thai accounts all retweeted @netiwitc's solidarity message — distributed participation"
        },
        {
          "type": "warning",
          "text": "EXTREME CLUSTERING: 89% of Thai tweets on Sept 20 alone — single-day viral campaign"
        },
        {
          "type": "info",
          "text": "ENGAGEMENT: Thai content got 40x more retweets than English — solidarity amplification in action"
        }
      ],
      "improvements": [
        "Cross-movement solidarity detection — non-local language spikes as solidarity indicator",
        "Temporal burst classifier — single-day >30% spikes need special handling",
        "Retweet cascade analysis — track amplification trees from source accounts",
        "Language anomaly alert — flag non-local >20% in geopolitical hashtags"
      ],
      "github_links": {
        "synthesis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/BELARUS_SYNTHESIS_RUN6.md"
      }
    },
    {
      "timestamp": "2026-02-19T18:40:00Z",
      "title": "Field Note: From Accident to Experiment to Fix",
      "method": "Methodological Observation",
      "type": "field_note",
      "summary": "We noticed only Claude had CommDAAF loaded — GLM and Kimi were running raw. Instead of just documenting it, we fixed it. Now all three models load the same methodology guardrails via opencode.json. Tonight's runs will be the first with true parity. We're turning an accident into a proper before/after comparison.",
      "findings": [
        {
          "type": "info",
          "text": "THE ACCIDENT: Runs 1-5 had Claude guided by CommDAAF, but GLM and Kimi got raw prompts with no methodology scaffolding."
        },
        {
          "type": "success",
          "text": "CONVERGENCE ANYWAY: All three found the same patterns (Cuba, Kashmir coordination, CNN law enforcement) — suggesting robust findings."
        },
        {
          "type": "success",
          "text": "THE FIX: Created opencode.json to load CommDAAF skill files. Updated cron jobs to run from skill-templates directory. All three models now equal."
        },
        {
          "type": "info",
          "text": "TONIGHT'S TEST: Runs 6+ will have all three models with CommDAAF. If outputs improve, framework helps. If same, guardrails prevent errors but don't change discovery."
        }
      ],
      "improvements": [
        "Created opencode.json to load SKILL.md + workflow files",
        "Added AGENTS.md summary for opencode context",
        "Updated cron jobs to run opencode from correct directory",
        "Now have before/after data: raw vs guided"
      ],
      "github_links": {
        "field_notes": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/FIELD_NOTES.md",
        "opencode_config": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/opencode.json"
      }
    },
    {
      "timestamp": "2026-02-19T17:23:00Z",
      "title": "Three AIs Analyzing Ukraine Crisis Data All Found the Same Surprise: Cuba",
      "method": "Pattern Detection",
      "dataset": "266,000 tweets about the Ukraine dam disaster (June 2023)",
      "analyst_model": "Claude, GLM-4, and Kimi (working independently)",
      "reviewer_model": "Cross-checked each other",
      "issues_found": 4,
      "summary": "We asked three different AI systems to analyze tweets about the Kakhovka dam breach — without telling them what to look for. All three, working completely independently, flagged the same unexpected pattern: Cuban government accounts were among the biggest amplifiers of content about a Ukrainian dam. Why is Cuba so interested in a dam in Ukraine?",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AIs FOUND IT: Cuban state media (@PartidoPCC, @DiazCanelB) showed up as major players — none of the AIs were told to look for this"
        },
        {
          "type": "success",
          "text": "AMPLIFICATION MACHINE: 72% of posts were retweets, not original thoughts — someone was boosting specific messages"
        },
        {
          "type": "warning",
          "text": "SUSPICIOUS TIMING: 1,390 accounts were created the exact week Russia invaded Ukraine — then went quiet until this crisis"
        },
        {
          "type": "warning",
          "text": "OFF-TOPIC INJECTION: Thousands of tweets about Biden and Burisma corruption appeared in a conversation about a dam collapse"
        },
        {
          "type": "info",
          "text": "The 'blame Russia' narrative outnumbered 'blame Ukraine' by 5 to 1"
        }
      ],
      "improvements": [
        "We should build a tool to automatically flag when unexpected countries show up in regional conflicts",
        "Track accounts that go dormant and suddenly reactivate during crises",
        "Detect when unrelated political content gets injected into breaking news"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/UKR_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-19T17:17:00Z",
      "title": "Was #KashmirWithModi Organic? Three AIs Say: Definitely Not",
      "method": "Coordination Analysis",
      "dataset": "99,000 tweets after India changed Kashmir's status (Aug 2019)",
      "analyst_model": "Claude, GLM-4, and Kimi (working independently)",
      "reviewer_model": "Cross-checked each other",
      "issues_found": 5,
      "summary": "When India revoked Kashmir's special status in 2019, #KashmirWithModi trended worldwide. Was this genuine public support or an organized campaign? We had three AIs investigate independently. Their verdict was unanimous: this has all the hallmarks of coordinated amplification.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AGREED: About 70% of tweets supported the government, only 1-2% were critical — that's a 50:1 ratio, which is extremely unusual"
        },
        {
          "type": "error",
          "text": "COPY-PASTE CAMPAIGN: The same 'Thank you Kashmiri Brothers' message was posted by 2,664 different accounts word-for-word"
        },
        {
          "type": "warning",
          "text": "FLASH MOB: 33,000+ tweets on a single day, then activity dropped 85% the next week — real movements don't evaporate that fast"
        },
        {
          "type": "warning",
          "text": "POWER USERS: 86 accounts were posting more than 10 times per hour — that's not normal human behavior"
        },
        {
          "type": "info",
          "text": "The campaign started 3 days AFTER the policy change — suggesting time to organize, not spontaneous reaction"
        }
      ],
      "improvements": [
        "Build a 'copy-paste detector' to flag when identical messages spread across many accounts",
        "Create alerts for unnatural posting speeds",
        "Track hashtag campaigns that spike and crash unnaturally fast"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/Kashmir_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-19T17:19:00Z",
      "title": "What CNN Covered in 2015: Three AIs Reach the Same Conclusion",
      "method": "Content Analysis",
      "dataset": "983 CNN articles from 2015",
      "analyst_model": "Claude, GLM-4, and Kimi (working independently)",
      "reviewer_model": "Cross-checked each other",
      "issues_found": 3,
      "summary": "2015 was a turbulent year in America — Ferguson protests, Baltimore unrest, the Charleston church shooting. We had three AIs analyze CNN's coverage to see what patterns emerge. All three found the same thing: law enforcement dominated nearly every story.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE FOUND: 87-94% of articles mentioned police, officers, or law enforcement — it was the lens for almost everything"
        },
        {
          "type": "success",
          "text": "TWO TYPES OF CONTENT: TV transcripts averaged 4,500 words; written articles averaged 700 words — you can't compare them directly"
        },
        {
          "type": "warning",
          "text": "NOT A RANDOM SAMPLE: June had 4x more articles than September because of the Charleston shooting — the data clusters around crises"
        },
        {
          "type": "warning",
          "text": "FRAMING DIFFERENCE: 'Black' appeared in victim/community contexts; 'White' appeared in perpetrator/officer contexts"
        },
        {
          "type": "info",
          "text": "Violence-related words appeared in 99.6% of all articles"
        }
      ],
      "improvements": [
        "Automatically detect when a dataset mixes different content types (like TV vs. print)",
        "Flag when data clusters around events instead of being evenly distributed",
        "Analyze not just what words appear, but what contexts they appear in"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/CNN_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-17T23:35:00Z",
      "title": "Two AIs Analyzed the Same Protest Data — Then Reviewed Each Other's Work",
      "method": "Network + Engagement Analysis",
      "dataset": "300,000 tweets from Nigeria's #EndSARS protests (Oct-Nov 2020)",
      "analyst_model": "GLM-4 and Kimi (working in parallel)",
      "reviewer_model": "Each AI reviewed the other's report",
      "issues_found": 5,
      "summary": "The #EndSARS movement against police brutality in Nigeria generated massive online activity. We had two AIs analyze the same protest data independently, then critique each other's findings. The peer review caught mistakes that neither AI found in its own work.",
      "findings": [
        {
          "type": "success",
          "text": "BOTH AGREED: The movement had thousands of participants but a handful of accounts drove most of the visibility"
        },
        {
          "type": "success",
          "text": "BOTH SAW THREE PHASES: Viral explosion → Steady engagement → Gradual decline over the two-week period"
        },
        {
          "type": "error",
          "text": "MATH ERROR CAUGHT: GLM said the correlation was 0.41; Kimi said 0.25 — turns out GLM forgot to account for the fact that follower counts are wildly skewed"
        },
        {
          "type": "warning",
          "text": "BLIND SPOT EXPOSED: GLM barely mentioned bots; Kimi found 10% of top activity came from accounts with 'Bot' literally in their names"
        },
        {
          "type": "info",
          "text": "Different interpretations: GLM saw 'solidarity'; Kimi saw 'safety-seeking behavior under authoritarianism' — both valid, neither complete"
        }
      ],
      "improvements": [
        "Always check if your data is skewed before calculating correlations",
        "Add a 'bot check' step that looks for obvious patterns in usernames",
        "When AIs disagree on interpretation, flag it for human review"
      ],
      "github_links": {
        "glm_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/red-teaming/sample-data/ENDSARS_ANALYSIS_GLM.md",
        "kimi_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/red-teaming/sample-data/ENDSARS_ANALYSIS_KIMI.md"
      }
    },
    {
      "timestamp": "2026-02-17T21:19:00Z",
      "title": "We Had Two AIs Analyze a TV Show's Tweets — Then They Tore Each Other Apart",
      "method": "Engagement Analysis",
      "analyst_model": "GLM-4",
      "reviewer_model": "Kimi",
      "issues_found": 4,
      "summary": "Before tackling sensitive political data, we tested our peer-review system on something simpler: 3,000 tweets from a TV show's official account. Even on this straightforward dataset, the cross-review process caught errors that would have slipped through otherwise.",
      "findings": [
        {
          "type": "success",
          "text": "BOTH AGREED: Tweets with hashtags got 3-4x more engagement, but the emotional tone of tweets didn't matter much"
        },
        {
          "type": "error",
          "text": "SIGN ERROR CAUGHT: Kimi said hashtags had a negative correlation (-0.40) but then concluded they INCREASE engagement — GLM spotted the contradiction"
        },
        {
          "type": "warning",
          "text": "EXAGGERATION FLAGGED: GLM called an effect 'large' when it was technically 'medium' by standard definitions — Kimi called it out"
        },
        {
          "type": "warning",
          "text": "HIDDEN SPIKE EXPLAINED: A 2017 'engagement surge' turned out to be 32 viral political retweets (about DACA), not actual show fans"
        },
        {
          "type": "info",
          "text": "Neither AI thought to account for Twitter's algorithm changes in 2016 — a blind spot for both"
        }
      ],
      "improvements": [
        "Double-check that conclusions match the direction of your statistics",
        "Use standard benchmarks when labeling effects as 'small,' 'medium,' or 'large'",
        "Look for external events that might explain sudden spikes in your data"
      ]
    },
    {
      "timestamp": "2026-02-17T21:00:00Z",
      "title": "Does Our AI Safety Net Actually Work? We Tested It",
      "method": "System Audit",
      "analyst_model": "GLM-4",
      "reviewer_model": "Kimi",
      "issues_found": 3,
      "summary": "CommDAAF is supposed to ask probing questions that catch methodological problems before analysis begins. But does it actually work? We deliberately fed it problematic data to see what it would catch — and what it would miss.",
      "findings": [
        {
          "type": "success",
          "text": "CAUGHT: The system correctly flagged that we were analyzing brand tweets but asking questions about audience sentiment — a fundamental mismatch"
        },
        {
          "type": "success",
          "text": "CAUGHT: Pre-calculated sentiment scores had no documentation — the system warned not to trust them"
        },
        {
          "type": "error",
          "text": "MISSED: One year in the dataset had only 3 data points — the system let us compare it to years with thousands"
        },
        {
          "type": "error",
          "text": "MISSED: Raw engagement numbers from 2014 vs 2018 can't be compared (Twitter changed how it counts) — the system didn't warn us"
        },
        {
          "type": "warning",
          "text": "MISSED: Hashtags and images affect engagement, but the system didn't remind us to control for them"
        }
      ],
      "improvements": [
        "Added a check: 'Does every time period have enough data to be meaningful?'",
        "Added a reminder: 'Raw social media metrics can't be compared across years'",
        "Added a checklist: 'What content features might be confounding your results?'"
      ]
    }
  ]
}
