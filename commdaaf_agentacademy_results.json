{
  "name": "AgentAcademy",
  "description": "Multi-model peer review incubator for CommDAAF — AI agents learn from mistakes through adversarial testing",
  "status": "active",
  "last_run": "2026-02-19T17:23:00Z",
  "next_run": "2026-02-20T05:00:00Z",
  "endpoint": "vineanalyst.com/commdaaf/agentacademy",
  "runs": [
    {
      "timestamp": "2026-02-19T17:23:00Z",
      "title": "Ukraine Kakhovka Dam: Three Models Independently Discover Cuban State Media Network",
      "method": "Coordination Detection + State Actor Analysis",
      "dataset": "266,242 tweets (June 7-9, 2023)",
      "analyst_model": "Claude + GLM-4.7 + Kimi K2.5 (3-model validation)",
      "reviewer_model": "Cross-model convergence",
      "issues_found": 4,
      "summary": "All three models independently discovered an unexpected finding: Cuban state media accounts formed a major amplification network in Ukraine dam crisis coverage. This cross-model convergence validates the finding's reliability.",
      "findings": [
        {
          "type": "success",
          "text": "THREE-MODEL CONVERGENCE: Claude, GLM, and Kimi all independently identified Cuban state media network (@PartidoPCC, @DiazCanelB, @CanalCaribeCuba)"
        },
        {
          "type": "success",
          "text": "COORDINATION METRICS: 72% retweet rate, 61,396 accounts created in 2022, @FuckPutinBot posted 2,926 tweets"
        },
        {
          "type": "warning",
          "text": "NARRATIVE INJECTION: Biden-Burisma corruption content (6,923 tweets) injected into humanitarian crisis coverage"
        },
        {
          "type": "warning",
          "text": "ACCOUNT CREATION SPIKE: 1,390 accounts created Feb 24-28, 2022 (invasion week) - potential sleeper accounts"
        },
        {
          "type": "info",
          "text": "Dam blame ratio 5:1 Russia vs Ukraine across all models"
        }
      ],
      "improvements": [
        "Add State-Actor Detection Module - track non-belligerent state media in conflict coverage",
        "Add Account Creation Spike Analysis - auto-detect clustering around geopolitical events",
        "Add Cross-Platform Content Fingerprinting - hash-based duplicate detection"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/UKR_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-19T17:17:00Z",
      "title": "Kashmir Article 370: Three Models Confirm Coordinated Amplification Campaign",
      "method": "Temporal + Coordination + Discourse Analysis",
      "dataset": "99,216 tweets (Aug 2019 - Jul 2020)",
      "analyst_model": "Claude + GLM-4.7 + Kimi K2.5 (3-model validation)",
      "reviewer_model": "Cross-model convergence",
      "issues_found": 5,
      "summary": "All three models found strong evidence of coordinated inauthentic behavior in #KashmirWithModi campaign. 70%+ pro-government content, massive text repetition, and extreme temporal concentration within 72 hours of Article 370 revocation.",
      "findings": [
        {
          "type": "success",
          "text": "THREE-MODEL CONVERGENCE: All found ~70% pro-government, ~1-2% critical voices (Claude: 107:1, GLM: 70.6%, Kimi: similar)"
        },
        {
          "type": "error",
          "text": "MASS DUPLICATION: Top message 'Thank you Kashmiri Brothers...' posted by 2,664+ unique accounts identically"
        },
        {
          "type": "warning",
          "text": "TEMPORAL BURST: 33,442 tweets on Aug 8 peak day, z-score 11.84 (Kimi), 85% decay by week 2"
        },
        {
          "type": "warning",
          "text": "HIGH-VELOCITY ACCOUNTS: 86 accounts posting >10 tweets/hour, 113 text templates used 100+ times each"
        },
        {
          "type": "info",
          "text": "Campaign started 3 days after Article 370 revocation - strategic timing, not organic reaction"
        }
      ],
      "improvements": [
        "Add Bot Probability Scoring - Botometer integration + velocity/repetition heuristics",
        "Add Temporal Anomaly Detection - auto-detect burst patterns and cross-account sync",
        "Add Multi-Hashtag Network Mapping - track coordinated hashtag ecosystems"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/Kashmir_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-19T17:19:00Z",
      "title": "CNN 2015: Three Models Agree on Law Enforcement Dominance and Framing Patterns",
      "method": "Content + Frame + Temporal Analysis",
      "dataset": "983 CNN articles (Jan-Dec 2015)",
      "analyst_model": "Claude + GLM-4.7 + Kimi K2.5 (3-model validation)",
      "reviewer_model": "Cross-model convergence",
      "issues_found": 3,
      "summary": "All three models converged on key findings: law enforcement dominates coverage (87-94%), transcripts are 6x longer than articles, and June 2015 Charleston shooting drove temporal spike. Event-driven sampling raises ecological validity concerns.",
      "findings": [
        {
          "type": "success",
          "text": "THREE-MODEL CONVERGENCE: Law enforcement in 87-94% of articles (Claude, GLM, Kimi all agree)"
        },
        {
          "type": "success",
          "text": "CONTENT TYPE BIAS: 37% transcripts (avg 4,480 words) vs 63% articles (avg 713 words) - 6x length difference"
        },
        {
          "type": "warning",
          "text": "EVENT-DRIVEN SAMPLING: June 2015 spike (171 articles) around Charleston shooting - not random sample"
        },
        {
          "type": "warning",
          "text": "RACIAL FRAMING: Near-parity mentions but asymmetric contexts - Black as victim/community, White as perpetrator"
        },
        {
          "type": "info",
          "text": "Violence terms in 99.6% of articles (Kimi finding)"
        }
      ],
      "improvements": [
        "Add Content Type Detection Module - detect transcripts vs articles before analysis",
        "Add Event-Spike Detection - flag anomalous temporal spikes to prevent ecological fallacies",
        "Add Keyword Co-occurrence Networks - move beyond frequencies to relational analysis"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/CNN_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-17T23:35:00Z",
      "title": "#EndSARS: Two AIs Discover Different Things in the Same Protest Data",
      "method": "Network + Temporal + Engagement Analysis",
      "dataset": "299,410 tweets from #EndSARS movement (Oct 21 - Nov 5, 2020)",
      "analyst_model": "GLM 4.7 + Kimi K2.5 (parallel)",
      "reviewer_model": "Cross-review (each reviewed the other)",
      "issues_found": 5,
      "summary": "We gave two AI researchers 10,000 tweets from the #EndSARS Nigerian protest movement (post-Lekki shooting) and asked them to independently analyze network structure, temporal dynamics, and engagement predictors. Then they reviewed each other's work. The cross-review caught a critical statistical methodology difference and a major blind spot.",
      "findings": [
        {
          "type": "success",
          "text": "Both AIs converged: Hybrid structure — decentralized participation (8,500+ users) but centralized amplification through @renoomokri, @AishaYesufu, @SaharaReporters"
        },
        {
          "type": "success",
          "text": "Both identified 3 distinct temporal phases with declining virality (7,345 → 3,969 → 2,469 avg RTs)"
        },
        {
          "type": "success",
          "text": "Both agreed: Follower count predicts engagement; content features (length, hashtags) don't matter in crisis contexts"
        },
        {
          "type": "error",
          "text": "CORRELATION DISCREPANCY: GLM reported r=0.412, Kimi reported r=0.251 — different because GLM used raw follower counts while Kimi log-transformed (correct for skewed Twitter data)"
        },
        {
          "type": "warning",
          "text": "BOT BLIND SPOT: GLM barely mentioned bots; Kimi found ~10% of top activity from @RTEndSars, @TheEndSarsBot, @sorosokebot"
        },
        {
          "type": "warning",
          "text": "GLM's phase classification contradicts itself — labeled 571 tweets/bin as 'Low' while 327 tweets/bin was 'Moderate'"
        },
        {
          "type": "info",
          "text": "Different theoretical frames: GLM emphasized 'solidarity signaling'; Kimi emphasized 'safety-seeking behavior in authoritarian context'"
        }
      ],
      "improvements": [
        "Always report both raw AND log-transformed correlations for skewed social media metrics",
        "Add bot detection checklist — username patterns, posting frequency, account age",
        "Require phase classification logic to be internally consistent",
        "Consider authoritarian context when interpreting high retweet rates"
      ],
      "github_links": {
        "glm_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/red-teaming/sample-data/ENDSARS_ANALYSIS_GLM.md",
        "kimi_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/red-teaming/sample-data/ENDSARS_ANALYSIS_KIMI.md",
        "glm_review": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/red-teaming/sample-data/ENDSARS_CROSSREVIEW_GLM.md",
        "kimi_review": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/red-teaming/sample-data/ENDSARS_CROSSREVIEW_KIMI.md"
      }
    },
    {
      "timestamp": "2026-02-17T21:19:00Z",
      "title": "Two AIs Analyzed the Same Data — Then Tore Each Other Apart",
      "method": "Sentiment + Engagement Analysis",
      "analyst_model": "GLM 4.7",
      "reviewer_model": "Kimi K2.5",
      "issues_found": 4,
      "summary": "We gave two AI researchers the same Twitter dataset (3,153 real tweets from a TV show's account) and asked them to independently discover research questions, run analyses, and write up findings. Then we had each one review the other's work. The cross-review caught errors that self-review completely missed.",
      "findings": [
        {
          "type": "success",
          "text": "Both AIs agreed: Hashtags boost engagement (3.5-3.8x more likes/retweets), but sentiment doesn't matter much"
        },
        {
          "type": "success", 
          "text": "Both identified 2016 as the real engagement peak — not 2017 as raw numbers suggested"
        },
        {
          "type": "error",
          "text": "Kimi reported a negative correlation (-0.40) but concluded hashtags INCREASE engagement — GLM caught this sign error"
        },
        {
          "type": "warning",
          "text": "GLM labeled an effect size as 'large' when it's technically 'medium' — Kimi called this out"
        },
        {
          "type": "warning",
          "text": "GLM found the 2017 'spike' was actually 32 viral political retweets (DACA content), not organic show engagement"
        },
        {
          "type": "info",
          "text": "Neither AI controlled for platform changes (Twitter's algorithm shift in 2016, character limit change in 2017)"
        }
      ],
      "improvements": [
        "Add 'platform change' checkpoint for 2014-2018 Twitter data",
        "Require explicit sign verification when reporting correlations",
        "Add standard effect size classification reference (small/medium/large thresholds)"
      ]
    },
    {
      "timestamp": "2026-02-17T21:00:00Z",
      "title": "Testing CommDAAF's Safety Net — What Did the Probing Questions Catch?",
      "method": "Probing Question Audit",
      "analyst_model": "GLM 4.7",
      "reviewer_model": "Kimi K2.5",
      "issues_found": 3,
      "summary": "We tested whether CommDAAF's built-in probing questions actually catch methodological problems when a researcher uses real data. The questions caught some critical issues but missed others entirely. Final grade: C+",
      "findings": [
        {
          "type": "success",
          "text": "CAUGHT: The dataset measures brand communication, not audience sentiment — a fundamental mismatch"
        },
        {
          "type": "success",
          "text": "CAUGHT: Pre-computed sentiment scores have unknown origin — can't trust them without validation"
        },
        {
          "type": "error",
          "text": "MISSED: 2018 only has 3 tweets — year-level comparisons are statistically meaningless"
        },
        {
          "type": "error",
          "text": "MISSED: No check for engagement normalization — raw likes/retweets can't be compared across years"
        },
        {
          "type": "warning",
          "text": "MISSED: No content controls — hashtags and media affect engagement but weren't factored out"
        }
      ],
      "improvements": [
        "Added temporal validity probe — check year distribution before allowing comparisons",
        "Added engagement normalization requirement",
        "Added content confound checklist (hashtags, media, mentions)",
        "NEW: Blockers now include 'INSTEAD, TRY...' alternatives so researchers can pivot to valid designs"
      ]
    }
  ],
  "technical_notes": {
    "glm_pty_fix": "2026-02-19: Discovered GLM via opencode requires PTY mode. Fixed with: exec pty:true command:\"cd /tmp && opencode run -m zai-coding-plan/glm-4.7 'prompt'\"",
    "censorship_findings": "GLM blocks China-domestic topics (HK, Xinjiang, Tibet) but allows India-Pakistan content (Kashmir, Article 370)"
  }
}
