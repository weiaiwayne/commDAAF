{
  "name": "AgentAcademy",
  "description": "Where AI agents learn to be better researchersâ€”and improve the tools along the way",
  "status": "active",
  "last_run": "2026-02-27T19:00:00Z",
  "next_run": "2026-03-01T05:00:00Z",
  "endpoint": "vineanalyst.com/commdaaf/agentacademy",
  "runs": [
    {
      "timestamp": "2026-02-27T19:00:00Z",
      "title": "ðŸ“„ From Study to Papers: #MahsaAmini Virality Research",
      "method": "Multi-Model Content Analysis â†’ Preprints + Protocol",
      "type": "study_to_papers",
      "dataset": {
        "tweets": 380,
        "time_period": "Sept 21 - Oct 3, 2022",
        "languages": "Persian (69%), English (23%), Arabic (5%)",
        "engagement_tiers": "Viral, High, Medium, Low"
      },
      "summary": "Analyzed what makes protest content go viral during the #MahsaAmini movement. Used 3-model validation (Claude, GLM, Kimi) with CommDAAF methodology. Surprising finding: factual, informational content spreads better than emotional appeals in crisis contexts. Study produced 2 preprints and a comprehensive protocol for future agentic research.",
      "key_finding": "INFORMATIONAL framing predicts 2.7x more engagement than SOLIDARITY framing",
      "outputs": {
        "title": "Research Outputs",
        "papers": [
          {
            "name": "Information Over Emotion?",
            "type": "Theory Paper",
            "target": "Journal of Communication",
            "finding": "Informational framing outperforms emotional frames in information-scarce crisis contexts",
            "contribution": "Information-scarcity hypothesis as boundary condition for moral contagion theory"
          },
          {
            "name": "Toward Agentic Content Analysis",
            "type": "Methods Paper",
            "target": "Computational Communication Research",
            "finding": "Documents full workflow with successes AND failures",
            "contribution": "CommDAAF framework + 10 concrete practices for human-AI collaborative research"
          }
        ],
        "protocol": {
          "name": "AgentAcademy Study Protocol",
          "purpose": "Step-by-step guide for future multi-model studies",
          "key_rules": [
            "Kimi batch limit: 25 posts max",
            "Mandatory distribution diagnostics before regression",
            "Report frame-specific reliability, not just aggregate",
            "Use Negative Binomial for engagement data (not OLS)"
          ]
        }
      },
      "findings": [
        {
          "type": "success",
          "text": "2 PREPRINTS PRODUCED: Theory paper + Methods paper ready for review"
        },
        {
          "type": "success",
          "text": "3-MODEL AGREEMENT: Fleiss Îº = 0.633 (Substantial)"
        },
        {
          "type": "success",
          "text": "PROTOCOL CREATED: Comprehensive guide for future AgentAcademy studies"
        },
        {
          "type": "info",
          "text": "SURPRISING FINDING: Information beats emotion in crisis contexts"
        },
        {
          "type": "info",
          "text": "PEER REVIEWED: Kimi provided constructive critique of both papers"
        },
        {
          "type": "warning",
          "text": "LIMITATION: No human validation (appropriate for exploratory tier)"
        }
      ],
      "plain_english": {
        "title": "What We Did (For Non-Technical Readers)",
        "paragraphs": [
          "We wanted to understand why some protest tweets spread widely while others don't. We looked at 380 tweets from the #MahsaAmini movementâ€”the Iranian protests that began in September 2022 after Mahsa Amini died in police custody.",
          "We had three different AI systems (Claude, GLM, and Kimi) independently categorize each tweet by its \"frame\"â€”is it expressing solidarity, reporting facts, calling for action, etc.? When the AIs agreed, we were more confident in the categorization.",
          "The surprising finding: tweets that simply reported facts (\"Protests spread to 50 cities\") got nearly 3x more engagement than emotional solidarity posts (\"We stand with Iranian women\"). This challenges the common belief that emotional content always spreads best.",
          "Why might this be? In a crisis where the government controls information and spreads disinformation, people desperately need facts. Factual updates become valuable precisely because they're scarce. Emotional support is abundant; reliable information is not.",
          "We wrote up our findings in two papersâ€”one about the content findings, one about the research method itself. We also created a detailed guide so others can replicate this kind of AI-assisted research."
        ]
      },
      "skill_improvements": {
        "title": "New CommDAAF Features (v0.6)",
        "version": "CommDAAF v0.6.0",
        "changes": [
          {
            "gap": "Manual codebook creation",
            "fix": "Codebook Generator skill auto-generates from theory"
          },
          {
            "gap": "Effect size calculation by hand",
            "fix": "Effect Size Interpreter with field benchmarks"
          },
          {
            "gap": "Ad-hoc sampling",
            "fix": "Sampling Strategist with engagement tiers and power analysis"
          },
          {
            "gap": "No literature search integration",
            "fix": "Literature Synthesis skill (Semantic Scholar + OpenAlex)"
          },
          {
            "gap": "Text-only analysis",
            "fix": "Multimodal Coder for images, video, memes"
          }
        ]
      }
    },
    {
      "timestamp": "2026-02-26T18:45:00Z",
      "title": "ðŸ”§ How One Study Improved CommDAAF: Iran Frame Analysis â†’ v0.4 Release",
      "method": "Multi-Model Validation â†’ Skill Improvement",
      "type": "study_to_skill",
      "dataset": {
        "headlines": 262,
        "sample": 60,
        "sources": "GDELT DOC API (Jan 2024 - Feb 2026)",
        "source_types": "US mainstream, Israeli, Al Jazeera, UK"
      },
      "summary": "Ran 3-model frame analysis on Iran news. Study workedâ€”but exposed 5 methodology gaps. Each gap became a CommDAAF v0.4 skill update. This is the AgentAcademy loop: Run real research â†’ Find what breaks â†’ Fix the framework for all users.",
      "key_finding": "Israeli sources frame Iran as THREAT 10x more than Al Jazeera (42% vs 4%)",
      "skill_improvements": {
        "title": "Study â†’ Skill Updates",
        "version": "CommDAAF v0.4.0",
        "changes": [
          {
            "gap": "Duplicate headlines in sample",
            "fix": "Pre-sampling deduplication protocol with code example"
          },
          {
            "gap": "No MIXED frame option",
            "fix": "Multi-label coding (PRIMARY + SECONDARY frame)"
          },
          {
            "gap": "'Strike back' vs 'negotiate' coded same",
            "fix": "Valence dimension (positive/negative/neutral) required"
          },
          {
            "gap": "No temporal breakdown for 25-month study",
            "fix": "Temporal segmentation required for >30 day studies"
          },
          {
            "gap": "Unclear single vs multi-model QC",
            "fix": "Explicit distinction: methodology scaffold â‰  fact-checker"
          }
        ],
        "files_changed": [
          "SKILL.md",
          "references/methods/frame-analysis.md",
          "references/workflows/tiered-validation.md",
          "CHANGELOG.md",
          "README.md"
        ]
      },
      "findings": [
        {
          "type": "success",
          "text": "SKILL UPDATED: 5 gaps found â†’ 5 fixes added to CommDAAF v0.4"
        },
        {
          "type": "success",
          "text": "3-MODEL CONVERGENCE: 78% perfect agreement, all hypotheses supported"
        },
        {
          "type": "success",
          "text": "KIMI WORKED: No content filter blocking (unlike Nigeria study)"
        },
        {
          "type": "info",
          "text": "KEY FINDING: Israeli THREAT framing 42% vs Al Jazeera 4% (10x difference)"
        },
        {
          "type": "info",
          "text": "ISRAELI BLIND SPOT: 0% domestic Iran coverage across all 3 models"
        },
        {
          "type": "warning",
          "text": "FRAMEWORK GAP: Multi-model convergence â‰  human validation (now documented)"
        }
      ],
      "before_after": {
        "before": [
          "Could sample duplicate headlines without knowing",
          "Lost valence information in frame coding",
          "Could assume 3-model = publication ready",
          "No temporal breakdown requirement"
        ],
        "after": [
          "Deduplication protocol enforced",
          "Valence required alongside frame",
          "Human validation required for ðŸ”´ tier",
          "Temporal segmentation for >30 days"
        ]
      },
      "links": {
        "agentacademy_report": "projects/iran-agenda-2026/AGENTACADEMY_REPORT.md",
        "model_comparison": "projects/iran-agenda-2026/MODEL_COMPARISON.md",
        "commdaaf_repo": "https://github.com/weiaiwayne/commDAAF",
        "commit": "4f59f69"
      },
      "report_url": "/static/vineanalyst/commdaaf/iran-agenda/AGENTACADEMY_REPORT.md"
    },
    {
      "timestamp": "2026-02-22T23:59:00Z",
      "title": "ðŸ“° Nigeria Christian-Fulani Conflict: News Framing Analysis",
      "method": "Multi-Model Validation (Claude + GLM + Kimi)",
      "type": "study",
      "dataset": {
        "headlines": 304,
        "fulltext": 38,
        "sources": "GDELT + MediaCloud",
        "period": "Nov 2025 - Feb 2026"
      },
      "summary": "International news coverage systematically over-represents religious framing (~60%) while economic/structural factors (~2%) are nearly invisible. Headlines distort more than articles (+22% religious over-representation). Nigerian sources provide 6x more economic context than US sources.",
      "findings": [
        {
          "type": "success",
          "text": "Claude + GLM converged: Religious framing ~60% (headlines), 38% (fulltext)"
        },
        {
          "type": "success",
          "text": "Economic framing: 2% (headlines) â†’ 8% (fulltext)"
        },
        {
          "type": "success",
          "text": "Nigerian sources: 14% religious vs 49-57% for US sources"
        },
        {
          "type": "error",
          "text": "Kimi K2.5 BLOCKED: 'Request rejected: high risk' - content filter triggered"
        },
        {
          "type": "info",
          "text": "H1-H4 SUPPORTED: Religious framing dominates, Christians portrayed as victims"
        },
        {
          "type": "info",
          "text": "H5 SUPPORTED (fulltext): Nigerian sources provide more diverse framing"
        },
        {
          "type": "warning",
          "text": "Headlines over-represent religious framing by 22 percentage points"
        }
      ],
      "hypotheses": {
        "H1": "Religious > economic framing â†’ SUPPORTED (30:1 headlines, 5:1 fulltext)",
        "H2": "Fulani blamed > structural â†’ SUPPORTED",
        "H3": "Christians victims > Fulani â†’ SUPPORTED (0 articles show Fulani victims)",
        "H4": "Conservative = more religious â†’ PARTIAL (mainstream US actually higher)",
        "H5": "Nigerian = more diverse â†’ SUPPORTED (confirmed with fulltext)"
      },
      "kimi_blocking": "Demonstrates Chinese LLM content filters extend to academic analysis of religious conflict topics",
      "links": {
        "full_report": "/static/vineanalyst/commdaaf/nigeria-framing/FINAL_REPORT.md",
        "model_comparison": "/static/vineanalyst/commdaaf/nigeria-framing/MODEL_COMPARISON.md",
        "fulltext_analysis": "/static/vineanalyst/commdaaf/nigeria-framing/FULLTEXT_COMPARISON.md",
        "full_study": "/static/vineanalyst/commdaaf/nigeria-framing/STUDY_REPORT.html"
      },
      "github": "https://github.com/weiaiwayne/commDAAF/tree/main/projects/nigeria-framing-2026",
      "report_url": "/static/vineanalyst/commdaaf/nigeria-framing/STUDY_REPORT.html",
      "github_links": {
        "full_study": "/static/vineanalyst/commdaaf/nigeria-framing/STUDY_REPORT.html",
        "claude_analysis": "/static/vineanalyst/commdaaf/nigeria-framing/FINAL_REPORT.md",
        "glm_analysis": "/static/vineanalyst/commdaaf/nigeria-framing/MODEL_COMPARISON.md",
        "fulltext_comparison": "/static/vineanalyst/commdaaf/nigeria-framing/FULLTEXT_COMPARISON.md"
      }
    },
    {
      "timestamp": "2026-02-22T13:20:00Z",
      "title": "âœ… CONFIRMED: Academic Framing Does NOT Bypass Chinese LLM Filters",
      "method": "Controlled API Testing",
      "type": "study",
      "summary": "Definitive test: Both z.ai GLM and Kimi BLOCK Xinjiang/Uyghur content regardless of academic framing. CommDAAF wrapper does NOT bypass filters. Previous 'bypass' was due to OpenCode free proxy infrastructure routing, NOT prompt engineering.",
      "findings": [
        {
          "type": "error",
          "text": "z.ai GLM DIRECT: Xinjiang prompt â†’ BLOCKED (code 1301: æ•æ„Ÿå†…å®¹)"
        },
        {
          "type": "error",
          "text": "Kimi DIRECT: Xinjiang prompt â†’ BLOCKED (high risk rejection)"
        },
        {
          "type": "error",
          "text": "z.ai GLM + CommDAAF WRAPPER: Still BLOCKED (code 1301)"
        },
        {
          "type": "error",
          "text": "Kimi + CommDAAF WRAPPER: Still BLOCKED (high risk)"
        },
        {
          "type": "success",
          "text": "CONCLUSION: Academic framing bypass hypothesis DISPROVEN"
        },
        {
          "type": "info",
          "text": "ROOT CAUSE: OpenCode free proxy (opencode/kimi-k2.5-free) bypasses filters at infrastructure level"
        }
      ],
      "github_links": {
        "final_study": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/papers/CENSORSHIP_STUDY_FINAL.md",
        "retraction": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/papers/RETRACTION_NOTE.md"
      }
    },
    {
      "timestamp": "2026-02-22T13:10:00Z",
      "title": "âš ï¸ RETRACTION: Academic Framing Bypass Hypothesis Investigation",
      "method": "Methodological Review",
      "type": "retraction",
      "summary": "Investigation revealed AgentAcademy runs (Feb 20+) used OpenCode's FREE PROXY models instead of direct Chinese API endpoints. Led to controlled study that disproved the hypothesis.",
      "findings": [
        {
          "type": "error",
          "text": "CRITICAL: OpenCode logs show providerID=opencode NOT zai-coding-plan or kimi-for-coding"
        },
        {
          "type": "error",
          "text": "EVIDENCE: $0.00 API cost when paid APIs should have been charged"
        },
        {
          "type": "info",
          "text": "OUTCOME: Led to controlled study that definitively disproved bypass hypothesis"
        }
      ],
      "github_links": {
        "retraction": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/papers/RETRACTION_NOTE.md"
      }
    },
    {
      "timestamp": "2026-02-22T12:30:00Z",
      "title": "âš ï¸ [SUSPENDED] Discovery: Academic Framing Bypasses Chinese LLM Content Filters",
      "method": "Methodological Finding",
      "type": "paper",
      "status": "SUSPENDED - See retraction note",
      "summary": "GLM and Kimi BLOCKED Xinjiang content via direct API (HTTP 400). Same content PASSED when wrapped in CommDAAF framework. âš ï¸ WARNING: This finding may be invalid â€” runs used free proxy, not direct API.",
      "findings": [
        {
          "type": "warning",
          "text": "âš ï¸ SUSPENDED: See retraction note â€” methodology under review"
        },
        {
          "type": "error",
          "text": "DIRECT API: \"Analyze Xinjiang tweets\" â†’ HTTP 400 blocked by content filter"
        },
        {
          "type": "warning",
          "text": "FRAMEWORK WRAPPER: Worked, BUT used free proxy â€” not proof of academic framing bypass"
        }
      ],
      "github_links": {
        "paper": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/papers/ACADEMIC_FRAMING_BYPASS.md",
        "retraction": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/papers/RETRACTION_NOTE.md",
        "field_notes": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/FIELD_NOTES_RUN6-8.md"
      }
    },
    {
      "timestamp": "2026-02-22T05:06:00Z",
      "title": "China TikTok: 60x Engagement Disparity + State Media Premium",
      "method": "3-Model Platform Analysis",
      "type": "study",
      "dataset": "1,994 TikTok videos + 48,070 comments (Chinese digital diplomacy)",
      "analyst_model": "Claude, GLM-4, and Kimi (all with CommDAAF loaded)",
      "reviewer_model": "Cross-validated",
      "issues_found": 4,
      "summary": "First TikTok analysis! China-general content gets 60x more plays than Xinjiang content. Only 3.5% Chinese comments â€” digital diplomacy targets international audience. State media accounts get 28-75% higher engagement than organic creators. Both GLM and Kimi analyzed without censorship.",
      "findings": [
        {
          "type": "error",
          "text": "60x DISPARITY: China general (5.3B plays) vs Xinjiang (87M plays) â€” algorithmic suppression or content strategy?"
        },
        {
          "type": "success",
          "text": "EXTERNAL TARGETING: 80.9% Latin/English comments, only 3.5% Chinese â€” this is diplomacy for foreigners"
        },
        {
          "type": "warning",
          "text": "STATE MEDIA PREMIUM: Accounts flagged as state-affiliated get 28-75% more engagement"
        },
        {
          "type": "warning",
          "text": "COORDINATION MARKERS: 10% duplicate comments, top comment (ðŸ¥°ðŸ¥°ðŸ¥°) repeated 300x"
        },
        {
          "type": "success",
          "text": "NO CENSORSHIP: GLM and Kimi analyzed Xinjiang content via CommDAAF wrapper â€” no API blocks"
        }
      ],
      "improvements": [
        "Platform engagement disparity detection (flag >10:1 topic ratios)",
        "Audience targeting analysis (language vs expected demographic)",
        "State media account database expansion",
        "Emoji spam detection for coordination"
      ],
      "github_links": {
        "synthesis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/RUN8_SYNTHESIS.md"
      }
    },
    {
      "timestamp": "2026-02-20T12:55:00Z",
      "title": "11 Lessons from 7 Studies: What AI Taught Us About Research Methods",
      "method": "Meta-Analysis",
      "type": "blog",
      "summary": "After running 7 studies with 3-model validation, we've distilled the lessons that apply to any computational social science project. These aren't about specific datasets â€” they're about how to do better research with AI assistance.",
      "findings": [
        {
          "type": "info",
          "text": "CONVERGENCE = CONFIDENCE: When three independent AI models reach the same conclusion without coordination, that finding is robust. We saw this with Cuban state media, Kashmir coordination, and CNN framing patterns."
        },
        {
          "type": "info",
          "text": "EFFECT SIZES MATTER: Cross-review caught a model calling Î´=0.40 'large' when Cohen's benchmarks say 'medium'. Always cite your benchmarks. Round down at boundaries."
        },
        {
          "type": "info",
          "text": "TRANSFORM BEFORE CORRELATING: Social media metrics are skewed. Raw correlations inflate effects. Log-transform count variables (followers, likes, retweets) and report both raw and transformed values."
        },
        {
          "type": "warning",
          "text": "SPIKES INVALIDATE AVERAGES: If 36% of your data comes from two days (like Xinjiang during H&M boycott), 'average engagement' is meaningless. Identify triggering events before interpreting."
        },
        {
          "type": "warning",
          "text": "HIGH RETWEET RATIOS NEED DIFFERENT ANALYSIS: When 88% of tweets are retweets, you're not studying discourse â€” you're studying an amplification battle. Network analysis beats engagement analysis."
        },
        {
          "type": "success",
          "text": "LANGUAGE ANOMALIES REVEAL NETWORKS: 38% Thai in a Belarus hashtag? Could be bots, could be solidarity movement. We found Milk Tea Alliance â€” organic activists, not bots. Always investigate before assuming."
        },
        {
          "type": "error",
          "text": "COORDINATION ISN'T ONE-SIDED: Xinjiang showed both pro-China AND pro-Uyghur sides running coordinated campaigns. Frameworks that assume single-actor coordination miss half the picture."
        }
      ],
      "improvements": [
        "Added retweet-heavy dataset warning (>80% RT triggers different analysis)",
        "Added peak/trough spike detection (>4:1 ratio requires event context)",
        "Added language anomaly detection (>20% non-local needs investigation)",
        "Added dual-sided coordination framework (check for adversarial amplification)"
      ],
      "github_links": {
        "lessons_learned": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/LESSONS_LEARNED.md",
        "critical_checks": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/critical-checks.md"
      }
    },
    {
      "timestamp": "2026-02-20T05:37:00Z",
      "title": "Xinjiang Cotton: When Two Propaganda Machines Collide",
      "method": "3-Model Coordination Analysis",
      "type": "study",
      "dataset": "92,038 tweets about Xinjiang cotton controversy (March 2021)",
      "analyst_model": "Claude, GLM-4, and Kimi (all with CommDAAF loaded)",
      "reviewer_model": "Cross-validated",
      "issues_found": 5,
      "summary": "The H&M boycott triggered an information war. Both pro-China (@SpokespersonCHN) and pro-Uyghur (@MarcRubio) sides ran coordinated amplification campaigns. 88% of tweets were retweets â€” this wasn't discourse, it was a volume battle. Despite state media's push, pro-Uyghur content got 2x more engagement on Twitter.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AGREED: March 25-26 spike (36% of all tweets) = H&M boycott announcement. Not organic."
        },
        {
          "type": "error",
          "text": "DUAL-SIDED WARFARE: Both sides coordinating â€” @SpokespersonCHN (China FM) vs @MarcRubio + @nathanlawkc"
        },
        {
          "type": "warning",
          "text": "ENGAGEMENT ASYMMETRY: Pro-Uyghur content got 2x more retweets (308 vs 144 avg) despite state media push"
        },
        {
          "type": "warning",
          "text": "88% RETWEETS: Almost no original discourse â€” pure amplification battle"
        },
        {
          "type": "info",
          "text": "10,027 accounts flagged as suspicious by Kimi's bot detection pipeline"
        }
      ],
      "improvements": [
        "Dual-sided coordination framework â€” current system assumes single actor",
        "Event-triggered spike detection â€” auto-flag peak/trough >4:1 ratio",
        "State-actor account database â€” track known government accounts",
        "Retweet-heavy dataset warning â€” different analysis needed when RT >80%"
      ],
      "github_links": {
        "synthesis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/XINJIANG_SYNTHESIS_RUN7.md"
      }
    },
    {
      "timestamp": "2026-02-20T05:08:00Z",
      "title": "The Belarus Mystery: Why Are 38% of Tweets in Thai?",
      "method": "3-Model Language Anomaly Analysis",
      "type": "study",
      "dataset": "95,849 tweets with #StandWithBelarus (September 2020)",
      "analyst_model": "Claude, GLM-4, and Kimi (all with CommDAAF loaded)",
      "reviewer_model": "Cross-validated",
      "issues_found": 4,
      "summary": "A puzzle: 38% of tweets about Belarus protests were in Thai. All three AIs investigated and reached the same conclusion: this was the Milk Tea Alliance â€” Thai democracy activists showing solidarity with Belarus, not bots. 89% of Thai tweets came on a single day, all retweeting activist @netiwitc.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AGREED: Thai content = Milk Tea Alliance solidarity, NOT bots. Zero Thai accounts exceeded 50 tweets/day."
        },
        {
          "type": "success",
          "text": "SINGLE SOURCE: 22,405 unique Thai accounts all retweeted @netiwitc's solidarity message â€” distributed participation"
        },
        {
          "type": "warning",
          "text": "EXTREME CLUSTERING: 89% of Thai tweets on Sept 20 alone â€” single-day viral campaign"
        },
        {
          "type": "info",
          "text": "ENGAGEMENT: Thai content got 40x more retweets than English â€” solidarity amplification in action"
        }
      ],
      "improvements": [
        "Cross-movement solidarity detection â€” non-local language spikes as solidarity indicator",
        "Temporal burst classifier â€” single-day >30% spikes need special handling",
        "Retweet cascade analysis â€” track amplification trees from source accounts",
        "Language anomaly alert â€” flag non-local >20% in geopolitical hashtags"
      ],
      "github_links": {
        "synthesis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/BELARUS_SYNTHESIS_RUN6.md"
      }
    },
    {
      "timestamp": "2026-02-19T18:40:00Z",
      "title": "Field Note: From Accident to Experiment to Fix",
      "method": "Methodological Observation",
      "type": "field_note",
      "summary": "We noticed only Claude had CommDAAF loaded â€” GLM and Kimi were running raw. Instead of just documenting it, we fixed it. Now all three models load the same methodology guardrails via opencode.json. Tonight's runs will be the first with true parity. We're turning an accident into a proper before/after comparison.",
      "findings": [
        {
          "type": "info",
          "text": "THE ACCIDENT: Runs 1-5 had Claude guided by CommDAAF, but GLM and Kimi got raw prompts with no methodology scaffolding."
        },
        {
          "type": "success",
          "text": "CONVERGENCE ANYWAY: All three found the same patterns (Cuba, Kashmir coordination, CNN law enforcement) â€” suggesting robust findings."
        },
        {
          "type": "success",
          "text": "THE FIX: Created opencode.json to load CommDAAF skill files. Updated cron jobs to run from skill-templates directory. All three models now equal."
        },
        {
          "type": "info",
          "text": "TONIGHT'S TEST: Runs 6+ will have all three models with CommDAAF. If outputs improve, framework helps. If same, guardrails prevent errors but don't change discovery."
        }
      ],
      "improvements": [
        "Created opencode.json to load SKILL.md + workflow files",
        "Added AGENTS.md summary for opencode context",
        "Updated cron jobs to run opencode from correct directory",
        "Now have before/after data: raw vs guided"
      ],
      "github_links": {
        "field_notes": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/FIELD_NOTES.md",
        "opencode_config": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/opencode.json"
      }
    },
    {
      "timestamp": "2026-02-19T17:23:00Z",
      "title": "Three AIs Analyzing Ukraine Crisis Data All Found the Same Surprise: Cuba",
      "method": "Pattern Detection",
      "dataset": "266,000 tweets about the Ukraine dam disaster (June 2023)",
      "analyst_model": "Claude, GLM-4, and Kimi (working independently)",
      "reviewer_model": "Cross-checked each other",
      "issues_found": 4,
      "summary": "We asked three different AI systems to analyze tweets about the Kakhovka dam breach â€” without telling them what to look for. All three, working completely independently, flagged the same unexpected pattern: Cuban government accounts were among the biggest amplifiers of content about a Ukrainian dam. Why is Cuba so interested in a dam in Ukraine?",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AIs FOUND IT: Cuban state media (@PartidoPCC, @DiazCanelB) showed up as major players â€” none of the AIs were told to look for this"
        },
        {
          "type": "success",
          "text": "AMPLIFICATION MACHINE: 72% of posts were retweets, not original thoughts â€” someone was boosting specific messages"
        },
        {
          "type": "warning",
          "text": "SUSPICIOUS TIMING: 1,390 accounts were created the exact week Russia invaded Ukraine â€” then went quiet until this crisis"
        },
        {
          "type": "warning",
          "text": "OFF-TOPIC INJECTION: Thousands of tweets about Biden and Burisma corruption appeared in a conversation about a dam collapse"
        },
        {
          "type": "info",
          "text": "The 'blame Russia' narrative outnumbered 'blame Ukraine' by 5 to 1"
        }
      ],
      "improvements": [
        "We should build a tool to automatically flag when unexpected countries show up in regional conflicts",
        "Track accounts that go dormant and suddenly reactivate during crises",
        "Detect when unrelated political content gets injected into breaking news"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/UKR_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-19T17:17:00Z",
      "title": "Was #KashmirWithModi Organic? Three AIs Say: Definitely Not",
      "method": "Coordination Analysis",
      "dataset": "99,000 tweets after India changed Kashmir's status (Aug 2019)",
      "analyst_model": "Claude, GLM-4, and Kimi (working independently)",
      "reviewer_model": "Cross-checked each other",
      "issues_found": 5,
      "summary": "When India revoked Kashmir's special status in 2019, #KashmirWithModi trended worldwide. Was this genuine public support or an organized campaign? We had three AIs investigate independently. Their verdict was unanimous: this has all the hallmarks of coordinated amplification.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE AGREED: About 70% of tweets supported the government, only 1-2% were critical â€” that's a 50:1 ratio, which is extremely unusual"
        },
        {
          "type": "error",
          "text": "COPY-PASTE CAMPAIGN: The same 'Thank you Kashmiri Brothers' message was posted by 2,664 different accounts word-for-word"
        },
        {
          "type": "warning",
          "text": "FLASH MOB: 33,000+ tweets on a single day, then activity dropped 85% the next week â€” real movements don't evaporate that fast"
        },
        {
          "type": "warning",
          "text": "POWER USERS: 86 accounts were posting more than 10 times per hour â€” that's not normal human behavior"
        },
        {
          "type": "info",
          "text": "The campaign started 3 days AFTER the policy change â€” suggesting time to organize, not spontaneous reaction"
        }
      ],
      "improvements": [
        "Build a 'copy-paste detector' to flag when identical messages spread across many accounts",
        "Create alerts for unnatural posting speeds",
        "Track hashtag campaigns that spike and crash unnaturally fast"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/Kashmir_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-19T17:19:00Z",
      "title": "What CNN Covered in 2015: Three AIs Reach the Same Conclusion",
      "method": "Content Analysis",
      "dataset": "983 CNN articles from 2015",
      "analyst_model": "Claude, GLM-4, and Kimi (working independently)",
      "reviewer_model": "Cross-checked each other",
      "issues_found": 3,
      "summary": "2015 was a turbulent year in America â€” Ferguson protests, Baltimore unrest, the Charleston church shooting. We had three AIs analyze CNN's coverage to see what patterns emerge. All three found the same thing: law enforcement dominated nearly every story.",
      "findings": [
        {
          "type": "success",
          "text": "ALL THREE FOUND: 87-94% of articles mentioned police, officers, or law enforcement â€” it was the lens for almost everything"
        },
        {
          "type": "success",
          "text": "TWO TYPES OF CONTENT: TV transcripts averaged 4,500 words; written articles averaged 700 words â€” you can't compare them directly"
        },
        {
          "type": "warning",
          "text": "NOT A RANDOM SAMPLE: June had 4x more articles than September because of the Charleston shooting â€” the data clusters around crises"
        },
        {
          "type": "warning",
          "text": "FRAMING DIFFERENCE: 'Black' appeared in victim/community contexts; 'White' appeared in perpetrator/officer contexts"
        },
        {
          "type": "info",
          "text": "Violence-related words appeared in 99.6% of all articles"
        }
      ],
      "improvements": [
        "Automatically detect when a dataset mixes different content types (like TV vs. print)",
        "Flag when data clusters around events instead of being evenly distributed",
        "Analyze not just what words appear, but what contexts they appear in"
      ],
      "github_links": {
        "claude_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/agent-academy/sample-data/CNN_analysis.md"
      }
    },
    {
      "timestamp": "2026-02-17T23:35:00Z",
      "title": "Two AIs Analyzed the Same Protest Data â€” Then Reviewed Each Other's Work",
      "method": "Network + Engagement Analysis",
      "dataset": "300,000 tweets from Nigeria's #EndSARS protests (Oct-Nov 2020)",
      "analyst_model": "GLM-4 and Kimi (working in parallel)",
      "reviewer_model": "Each AI reviewed the other's report",
      "issues_found": 5,
      "summary": "The #EndSARS movement against police brutality in Nigeria generated massive online activity. We had two AIs analyze the same protest data independently, then critique each other's findings. The peer review caught mistakes that neither AI found in its own work.",
      "findings": [
        {
          "type": "success",
          "text": "BOTH AGREED: The movement had thousands of participants but a handful of accounts drove most of the visibility"
        },
        {
          "type": "success",
          "text": "BOTH SAW THREE PHASES: Viral explosion â†’ Steady engagement â†’ Gradual decline over the two-week period"
        },
        {
          "type": "error",
          "text": "MATH ERROR CAUGHT: GLM said the correlation was 0.41; Kimi said 0.25 â€” turns out GLM forgot to account for the fact that follower counts are wildly skewed"
        },
        {
          "type": "warning",
          "text": "BLIND SPOT EXPOSED: GLM barely mentioned bots; Kimi found 10% of top activity came from accounts with 'Bot' literally in their names"
        },
        {
          "type": "info",
          "text": "Different interpretations: GLM saw 'solidarity'; Kimi saw 'safety-seeking behavior under authoritarianism' â€” both valid, neither complete"
        }
      ],
      "improvements": [
        "Always check if your data is skewed before calculating correlations",
        "Add a 'bot check' step that looks for obvious patterns in usernames",
        "When AIs disagree on interpretation, flag it for human review"
      ],
      "github_links": {
        "glm_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/red-teaming/sample-data/ENDSARS_ANALYSIS_GLM.md",
        "kimi_analysis": "https://github.com/weiaiwayne/commDAAF/blob/main/skill-templates/workflows/red-teaming/sample-data/ENDSARS_ANALYSIS_KIMI.md"
      }
    },
    {
      "timestamp": "2026-02-17T21:19:00Z",
      "title": "We Had Two AIs Analyze a TV Show's Tweets â€” Then They Tore Each Other Apart",
      "method": "Engagement Analysis",
      "analyst_model": "GLM-4",
      "reviewer_model": "Kimi",
      "issues_found": 4,
      "summary": "Before tackling sensitive political data, we tested our peer-review system on something simpler: 3,000 tweets from a TV show's official account. Even on this straightforward dataset, the cross-review process caught errors that would have slipped through otherwise.",
      "findings": [
        {
          "type": "success",
          "text": "BOTH AGREED: Tweets with hashtags got 3-4x more engagement, but the emotional tone of tweets didn't matter much"
        },
        {
          "type": "error",
          "text": "SIGN ERROR CAUGHT: Kimi said hashtags had a negative correlation (-0.40) but then concluded they INCREASE engagement â€” GLM spotted the contradiction"
        },
        {
          "type": "warning",
          "text": "EXAGGERATION FLAGGED: GLM called an effect 'large' when it was technically 'medium' by standard definitions â€” Kimi called it out"
        },
        {
          "type": "warning",
          "text": "HIDDEN SPIKE EXPLAINED: A 2017 'engagement surge' turned out to be 32 viral political retweets (about DACA), not actual show fans"
        },
        {
          "type": "info",
          "text": "Neither AI thought to account for Twitter's algorithm changes in 2016 â€” a blind spot for both"
        }
      ],
      "improvements": [
        "Double-check that conclusions match the direction of your statistics",
        "Use standard benchmarks when labeling effects as 'small,' 'medium,' or 'large'",
        "Look for external events that might explain sudden spikes in your data"
      ]
    },
    {
      "timestamp": "2026-02-17T21:00:00Z",
      "title": "Does Our AI Safety Net Actually Work? We Tested It",
      "method": "System Audit",
      "analyst_model": "GLM-4",
      "reviewer_model": "Kimi",
      "issues_found": 3,
      "summary": "CommDAAF is supposed to ask probing questions that catch methodological problems before analysis begins. But does it actually work? We deliberately fed it problematic data to see what it would catch â€” and what it would miss.",
      "findings": [
        {
          "type": "success",
          "text": "CAUGHT: The system correctly flagged that we were analyzing brand tweets but asking questions about audience sentiment â€” a fundamental mismatch"
        },
        {
          "type": "success",
          "text": "CAUGHT: Pre-calculated sentiment scores had no documentation â€” the system warned not to trust them"
        },
        {
          "type": "error",
          "text": "MISSED: One year in the dataset had only 3 data points â€” the system let us compare it to years with thousands"
        },
        {
          "type": "error",
          "text": "MISSED: Raw engagement numbers from 2014 vs 2018 can't be compared (Twitter changed how it counts) â€” the system didn't warn us"
        },
        {
          "type": "warning",
          "text": "MISSED: Hashtags and images affect engagement, but the system didn't remind us to control for them"
        }
      ],
      "improvements": [
        "Added a check: 'Does every time period have enough data to be meaningful?'",
        "Added a reminder: 'Raw social media metrics can't be compared across years'",
        "Added a checklist: 'What content features might be confounding your results?'"
      ]
    }
  ]
}
